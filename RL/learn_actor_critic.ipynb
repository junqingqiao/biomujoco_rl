{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn Actor Crititc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mediapy as media\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../Biodiffrl\")\n",
    "import nn\n",
    "import experience\n",
    "\n",
    "import os\n",
    "# os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \".60\"\n",
    "\n",
    "# Optionally, force JAX to preallocate memory.\n",
    "# os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"true\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "\n",
    "# Setup environment variable for Nvidia GPU acceleration\n",
    "os.environ['XLA_FLAGS'] = (\n",
    "    '--xla_gpu_triton_gemm_any=True '\n",
    ")\n",
    "backend = 'gpu'\n",
    "# backend = 'METAL'\n",
    "# backend = 'cpu'\n",
    "\n",
    "import jax\n",
    "from jax import numpy as jp\n",
    "\n",
    "import optax\n",
    "\n",
    "\n",
    "# Enable compliation catch\n",
    "jax.config.update(\"jax_compilation_cache_dir\", \"./jax_cache\")\n",
    "jax.config.update(\"jax_persistent_cache_min_entry_size_bytes\", 0)\n",
    "jax.config.update(\"jax_persistent_cache_min_compile_time_secs\", 5)\n",
    "# jax.config.update(\"jax_explain_cache_misses\", True)\n",
    "\n",
    "# Debug Nan\n",
    "jax.config.update(\"jax_debug_nans\", False)\n",
    "\n",
    "\n",
    "# More legible printing from numpy.\n",
    "jp.set_printoptions(precision=4, suppress=True, linewidth=100)\n",
    "\n",
    "import mujoco\n",
    "import mujoco.mjx as mjx\n",
    "from mujoco.mjx._src import scan\n",
    "from mujoco.mjx._src import types\n",
    "\n",
    "# More legible printing from numpy.\n",
    "np.set_printoptions(precision=4, suppress=True, linewidth=100)\n",
    "\n",
    "from IPython.display import clear_output\n",
    "clear_output()\n",
    "\n",
    "device = jax.devices(backend=backend)[0]\n",
    "\n",
    "model_path = '../model/inverted_pendulum.xml'\n",
    "\n",
    "# Single step\n",
    "mjx_step = jax.jit(mjx.step, backend=backend)\n",
    "\n",
    "\n",
    "\n",
    "# mjx_multiple_steps = jax.jit(multiple_steps, backend=backend, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mujoco.mjx._src.biomtu import acceleration_mtu\n",
    "\n",
    "mj_model = mujoco.MjModel.from_xml_path(model_path)\n",
    "mjx_model = mjx.put_model(mj_model,device=device)\n",
    "\n",
    "# Disable tendon\n",
    "opt = mjx_model.opt.replace(disableflags = mjx_model.opt.disableflags |mujoco.mjtDisableBit.mjDSBL_PASSIVE)\n",
    "mjx_model = mjx_model.replace(opt=opt)\n",
    "\n",
    "mjx_data = mjx.make_data(mjx_model)\n",
    "mj_data = mujoco.MjData(mj_model)\n",
    "\n",
    "# Load the Keyframe\n",
    "# mjx_data = mjx_data.replace(qpos = mj_model.key_qpos[0])\n",
    "# mj_data.qpos = mj_model.key_qpos[0]\n",
    "\n",
    "# Calculate equilibrum\n",
    "# mjx_data = acceleration_mtu.calc_equilibrium(mjx_model, mjx_data)\n",
    "mjx_data = mjx_step(mjx_model, mjx_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control Neural Network and Critic Neural Network\n",
    "For now this NN will only work for the inverted pendulum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Controller NN\n",
    "key = jax.random.key(2024)\n",
    "controller_nn = nn.Controller_NN(mjx_model.nq*2, 1)\n",
    "controller_param, key = controller_nn.init_parameters(key)\n",
    "controller = controller_nn.get_fn()\n",
    "\n",
    "# Critic NN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class Critic_NN(nn.Module):\n",
    "\n",
    "    def setup(self):\n",
    "        # Features means the output dimension\n",
    "        self.linear1 = nn.Dense(features=400)\n",
    "        self.linear2 = nn.Dense(features=400)\n",
    "        self.linear3 = nn.Dense(features=400)\n",
    "        self.linear4 = nn.Dense(features=400)\n",
    "        # The last layer will output the mean and logstd\n",
    "        self.linear5 = nn.Dense(features=1)\n",
    "        \n",
    "    \n",
    "    def __call__(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = nn.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = nn.relu(x)\n",
    "        x = self.linear3(x)\n",
    "        x = nn.relu(x)\n",
    "        x = self.linear4(x)\n",
    "        x = nn.relu(x)\n",
    "        x = self.linear5(x)\n",
    "        # The last layer of the neural requires samping\n",
    "        return -nn.relu(x)\n",
    "\n",
    "critic = Critic_NN()\n",
    "\n",
    "# Init the critic neural network by providing the input dummy. The input dummy defines the input shape\n",
    "key = jax.random.split(sub_keys[0],1)[0]\n",
    "sub_key = jax.random.split(key,1)[0]\n",
    "\n",
    "# The input for the qcritic neural network should be observations and actions\n",
    "# For the obs=mjx_model.nq*2, actions=1\n",
    "critic_params = critic.init(key, jp.empty([1,mjx_model.nq*2]))\n",
    "jit_critic = jax.jit(lambda params, state_acts: critic.apply(params, state_acts))\n",
    "\n",
    "# Test the two neural networks\n",
    "print(jit_controller(controller_params, jp.ones(mjx_model.nq*2), sub_keys[0]))\n",
    "print(jit_critic(critic_params, jp.ones(mjx_model.nq*2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import functools\n",
    "\n",
    "\n",
    "# Register the Experience class as pytree\n",
    "@functools.partial(jax.tree_util.register_dataclass,\n",
    "                   data_fields=['states', 'next_states', 'actions', 'rewards'],\n",
    "                   meta_fields=[])\n",
    "@dataclass\n",
    "class Experience(object):\n",
    "    states : jax.Array\n",
    "    next_states : jax.Array\n",
    "    actions : jax.Array\n",
    "    rewards : jax.Array\n",
    "    # dones: jax.Array\n",
    "    \n",
    "    # def __init__(self, state, next_state, action, reward):\n",
    "    #     self.state = state\n",
    "    #     self.next_state = next_state\n",
    "    #     self.action = action\n",
    "    #     self.reward = reward\n",
    "\n",
    "\n",
    "\n",
    "@functools.partial(jax.tree_util.register_dataclass,\n",
    "                   data_fields=['max_size', 'state_shape', 'action_shape', 'reward_shape'],\n",
    "                   meta_fields=[])\n",
    "@dataclass(frozen=True)\n",
    "class Memory_settings():\n",
    "    max_size     : jax.Array\n",
    "    state_shape  : jax.Array\n",
    "    action_shape : jax.Array\n",
    "    reward_shape : jax.Array\n",
    "\n",
    "\n",
    "class Memory(): \n",
    "    \n",
    "    @staticmethod\n",
    "    def append_fn(exp_item, exp_pool_item):\n",
    "        return jp.concatenate([exp_item, exp_pool_item],axis=0)\n",
    "    \n",
    "    @staticmethod\n",
    "    def trim_fn(exp_pool_item, length):\n",
    "        return exp_pool_item[:length]\n",
    "    \n",
    "    @staticmethod\n",
    "    def sample_fn(exp_pool_item, index):\n",
    "        return exp_pool_item[index]\n",
    "    \n",
    "    staticmethod\n",
    "    @functools.partial(jax.jit, static_argnames=\"settings\")\n",
    "    def add_exp(settings:Memory_settings, exp_pool:Experience, exp:Experience):\n",
    "        exp.states = jp.reshape(exp.states,(-1, settings.state_shape))\n",
    "        exp.next_states = jp.reshape(exp.next_states,(-1, settings.state_shape))\n",
    "        exp.actions = jp.reshape(exp.actions, (-1, settings.action_shape))\n",
    "        exp.rewards = jp.reshape(exp.rewards, (-1, settings.reward_shape))\n",
    "        \n",
    "        if(exp_pool == None):\n",
    "            exp_pool = exp\n",
    "        else:\n",
    "            exp_pool = jax.tree.map(Memory.append_fn, exp, exp_pool)\n",
    "            \n",
    "        len = exp_pool.states.shape[0]\n",
    "        \n",
    "        # Forget the outdated memory\n",
    "        if(len> settings.max_size):\n",
    "            exp_pool = jax.tree.map(lambda x: Memory.trim_fn(x, settings.max_size), exp_pool)\n",
    "        \n",
    "        return exp_pool\n",
    "        \n",
    "    @staticmethod\n",
    "    @functools.partial(jax.jit, static_argnames=\"batch_size\")\n",
    "    def sample(exp_pool, batch_size, key)-> Experience :\n",
    "        index = jax.random.choice(\n",
    "            key,\n",
    "            jp.arange(exp_pool.states.shape[0]),\n",
    "            shape = (batch_size,),\n",
    "            replace=False\n",
    "        )\n",
    "        return jax.tree.map(lambda x: Memory.sample_fn(x, index), exp_pool)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-steps forward simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_fn(carry, _):\n",
    "    data, model = carry\n",
    "    new_data = mjx.step(model, data)\n",
    "    new_carry = (new_data, model)\n",
    "    return new_carry, _\n",
    "\n",
    "def multiple_steps(model, data):\n",
    "    init_carry = (data, model)\n",
    "    y, _ = jax.lax.scan(step_fn, init_carry, None, length=10)\n",
    "    new_data = y[0]\n",
    "    return new_data\n",
    "\n",
    "def nn_mjx_one_step(nn_params, model, data, key):\n",
    "    states = jp.concatenate([data.qpos, data.qvel])\n",
    "    act, mean, dev = jit_controller(nn_params, states, key)\n",
    "    # Generate the next key\n",
    "    new_key = jax.random.split(key,1)[0]\n",
    "    data = data.replace(ctrl = jp.array([act]))\n",
    "    new_data = mjx.step(model, data)\n",
    "    return new_data, new_key, act\n",
    "\n",
    "@jax.jit\n",
    "def jit_nn_mjx_one_step_no_random(nn_params, model, data, key):\n",
    "    states = jp.concatenate([data.qpos, data.qvel])\n",
    "    act, mean, dev = jit_controller(nn_params, states, key)\n",
    "    # Generate the next key\n",
    "    new_key = jax.random.split(key,1)[0]\n",
    "    data = data.replace(ctrl = jp.array([mean]))\n",
    "    new_data = mjx.step(model, data)\n",
    "    return new_data, new_key, mean\n",
    "\n",
    "def nn_step_fn(carry, _):\n",
    "    nn_params, model, data, key = carry\n",
    "    new_data, new_key, act = nn_mjx_one_step(nn_params, model, data, key)\n",
    "    new_carry = (nn_params, model, new_data, new_key)\n",
    "    # Calculate reward\n",
    "    state = jp.stack([data.qpos, data.qvel], axis=1).flatten()\n",
    "    next_state = jp.stack([new_data.qpos, data.qvel], axis=1).flatten()\n",
    "    action = act\n",
    "    reward = -new_data.qpos[1]**2\n",
    "    experience = Experience(state, next_state, action, reward)\n",
    "    \n",
    "    return new_carry, experience\n",
    "\n",
    "def decay_sum_scan(x, decay):\n",
    "    def f(sxtm1, xt):\n",
    "        b = xt + decay * sxtm1\n",
    "        return b, b\n",
    "    return jax.lax.scan(f, jp.zeros(x.shape[1:]), x)[1]\n",
    "\n",
    "@jax.jit\n",
    "def jit_nn_multi_steps(nn_params, model, data, key):\n",
    "    repeat_length = 5\n",
    "    init_carry = (nn_params, model, data, key)\n",
    "    y, experience = jax.lax.scan(nn_step_fn, init_carry, None, length=repeat_length)\n",
    "    new_data = y[2]\n",
    "    new_key = y[3]\n",
    "    \n",
    "    return new_data, new_key, experience\n",
    "\n",
    "@jax.jit\n",
    "def jit_v_nn_multi_steps(nn_params, model, data, key):\n",
    "    return jax.vmap(jit_nn_multi_steps, in_axes=(None, None, 0, 0))(nn_params, model, data, key)\n",
    "\n",
    "# This function generate\n",
    "@jax.jit\n",
    "def jit_vv_nn_multi_steps(nn_params, model, data, key):\n",
    "    return jax.vmap(jit_v_nn_multi_steps, in_axes=(None, None, None, 1))(nn_params, model, data, key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short Horizon Simulation & Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Control "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @jax.jit\n",
    "def reset(model, batch_size):\n",
    "    batch_dummy = jp.zeros(batch_size)\n",
    "    v_make_data = jax.jit(jax.vmap(lambda model, batch_dummy: mjx.make_data(model), in_axes=(None,0),out_axes=0))\n",
    "    new_datas = v_make_data(model, batch_dummy)\n",
    "    return new_datas\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the model and controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mujoco.viewer\n",
    "import time\n",
    "\n",
    "\n",
    "mjx_data = mjx.make_data(mjx_model)\n",
    "mj_data = mujoco.MjData(mj_model)\n",
    "previous_frame_time = time.time()\n",
    "i = 0\n",
    "key = jax.random.key(334)\n",
    "with mujoco.viewer.launch_passive(mj_model, mj_data) as viewer:\n",
    "    while viewer.is_running():\n",
    "        # Update mjx_data from mj_data. The mj_data was modified by the viewer\n",
    "        # mjx_data = mjx_data.replace(ctrl=mj_data.ctrl, xfrc_applied=mj_data.xfrc_applied)\n",
    "        # Use the nerual network to generate ctrl signal\n",
    "        # Generate key\n",
    "        mjx_data = mjx_data.replace(xfrc_applied=jp.array(mj_data.xfrc_applied, dtype=jp.float32))\n",
    "        mjx_data = mjx_data.replace(\n",
    "            qpos= jp.array(mj_data.qpos, dtype=jp.float32),\n",
    "            qvel= jp.array(mj_data.qvel, dtype=jp.float32),\n",
    "            time = jp.array(mj_data.time, dtype=jp.float32))\n",
    "        \n",
    "        # Update mjx_model from mj_model\n",
    "        mjx_model = mjx_model.tree_replace({\n",
    "            'opt.gravity': jp.array(mj_model.opt.gravity, dtype=jp.float32),\n",
    "            'opt.tolerance': jp.array(mj_model.opt.tolerance, dtype=jp.float32),\n",
    "            'opt.ls_tolerance': jp.array(mj_model.opt.ls_tolerance, dtype=jp.float32),\n",
    "            'opt.timestep': jp.array(mj_model.opt.timestep, dtype=jp.float32),\n",
    "        })\n",
    "        \n",
    "        key = jax.random.split(key,1)[0]\n",
    "        # mjx_data = mjx_step(mjx_model, mjx_data)\n",
    "        # mjx_data, loss, exp = jit_nn_multi_steps(controller_params, mjx_model, mjx_data, key)\n",
    "        mjx_data, key, act = jit_nn_mjx_one_step_no_random(controller_params, mjx_model, mjx_data, key)\n",
    "        mjx.get_data_into(mj_data, mj_model, mjx_data)\n",
    "        \n",
    "        # Record the current time at the start of this frame\n",
    "        current_frame_time = time.time()\n",
    "    \n",
    "        # Calculate the difference in time from the last frame\n",
    "        time_between_frames = current_frame_time - previous_frame_time\n",
    "    \n",
    "        # Print the time between frames\n",
    "        print(f\"Time between frames: {time_between_frames} seconds\")\n",
    "        previous_frame_time = current_frame_time\n",
    "        \n",
    "        # print(\"ACT:\", mjx_data.biomtu.act)\n",
    "        # print(mjx_data.qpos)\n",
    "        # print(mjx_data.sensordata)\n",
    "        # print(len(mjx_data.qvel))\n",
    "        viewer.sync()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test generate branch by stochastic policy neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.key(1234)\n",
    "memory_settings = Memory_settings(50000, 4, 1, 1)\n",
    "exp_pool = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's generate some observations and rewards\n",
    "\n",
    "def reshape_data(datas, batch_size, fock_size):\n",
    "    def fn(data):\n",
    "        new_shape = [*(data.shape)][1:]\n",
    "        new_shape[0]=batch_size*fock_size\n",
    "        # print(new_shape)\n",
    "        return data.reshape(new_shape)\n",
    "    return jax.tree.map(fn,datas)\n",
    "\n",
    "\n",
    "\n",
    "init_batch_size = 10\n",
    "batch_size = init_batch_size\n",
    "fock_size = 10\n",
    "\n",
    "# Start with the fixed init state\n",
    "keys = jax.random.split(key, batch_size)\n",
    "datas = reset(mjx_model,batch_size)\n",
    "\n",
    "\n",
    "# print(datas.qpos)\n",
    "for i in range(10):    # For 2 seconds\n",
    "    datas, keys, exp = jit_v_nn_multi_steps(controller_params, mjx_model, datas, keys)\n",
    "    # print(datas.qvel.shape, datas.ten_J.shape)\n",
    "    if(i == 2):    # After 0.5 seconds fock the simulation\n",
    "        keys = jax.vmap(jax.random.split, in_axes=(0,None))(keys, fock_size)\n",
    "        datas, keys, exp = jit_vv_nn_multi_steps(controller_params, mjx_model, datas, keys)\n",
    "        keys = keys.reshape(batch_size*fock_size)\n",
    "        datas = reshape_data(datas, batch_size, fock_size)\n",
    "        exp = reshape_data(exp, batch_size, fock_size)\n",
    "        # print(datas.qvel.shape, datas.ten_J.shape)\n",
    "        batch_size = batch_size*fock_size\n",
    "    exp_pool = Memory.add_exp(memory_settings, exp_pool, exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# print(exp_pool)\n",
    "print(exp_pool.states.shape)\n",
    "key = jax.random.split(key, 1)[0]\n",
    "batch = Memory.sample(exp_pool, 100, key)\n",
    "key = jax.random.split(key, 1)[0]\n",
    "print(batch.states[:,0:2].shape)\n",
    "print(datas.qpos.shape)\n",
    "plt.plot(exp_pool.states.T[1])\n",
    "plt.plot(exp_pool.rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the critic neural network with generated data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import flax.linen\n",
    "\n",
    "\n",
    "v_critic = jax.vmap(critic.apply,in_axes=(None, 0))\n",
    "\n",
    "\n",
    "def critic_loss(params, batch):\n",
    "    discount = 0.95\n",
    "    states = batch.states\n",
    "    next_states = batch.next_states\n",
    "    actions = batch.actions\n",
    "    rewards = batch.rewards\n",
    "    \n",
    "    critic_score = v_critic(params, states)\n",
    "    target = rewards + discount* critic.apply(params, next_states)\n",
    "    \n",
    "    loss = optax.l2_loss(critic_score, target)\n",
    "    loss = jp.mean(loss)\n",
    "    return loss\n",
    "    \n",
    "jit_critic_loss_value = jax.jit(jax.value_and_grad(critic_loss))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Critic_NN parameters\n",
    "critic_params = critic.init(key, jp.empty([1,mjx_model.nq*2]))\n",
    "tx = optax.adam(learning_rate=0.00002)\n",
    "opt_state = tx.init(critic_params)\n",
    "jit_tx_update = jax.jit(tx.update)\n",
    "jit_apply_update = jax.jit(optax.apply_updates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(2000):\n",
    "    batch = Memory.sample(exp_pool, 40, key)\n",
    "    key = jax.random.split(key, 1)[0]\n",
    "    loss, loss_grad = jit_critic_loss_value(critic_params, batch)\n",
    "    print(loss)\n",
    "    # Update params\n",
    "    updates, opt_stats = jit_tx_update(loss_grad, opt_state)\n",
    "    critic_params = jit_apply_update(critic_params, updates)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the critic neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jit_v_critic = jax.jit(v_critic)\n",
    "test_states = exp_pool.states\n",
    "\n",
    "# test_states = test_states.at[:,0].set(jp.zeros(test_states.shape[0]))\n",
    "test_states = test_states.at[:,1].set(jp.zeros(test_states.shape[0]))\n",
    "test_states = test_states.at[:,2].set(jp.zeros(test_states.shape[0]))\n",
    "test_states = test_states.at[:,3].set(jp.zeros(test_states.shape[0]))\n",
    "scores = jit_v_critic(critic_params, exp_pool.states)\n",
    "test_scores = jit_v_critic(critic_params, test_states)\n",
    "\n",
    "plt.plot(scores)\n",
    "plt.plot(test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the controller with the critic net without the differentiable simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Params\n",
    "controller_params = controller.init(key,jp.empty([1, mjx_model.nq*2]),sub_keys[0])\n",
    "tx = optax.adam(learning_rate=0.00001)\n",
    "opt_state = tx.init(controller_params)\n",
    "jit_tx_update = jax.jit(tx.update)\n",
    "jit_apply_update = jax.jit(optax.apply_updates)\n",
    "batch_size = 400\n",
    "# Init data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_controller = jax.vmap(controller.apply,in_axes=(None, 0))\n",
    "\n",
    "\n",
    "def total_loss(controller_params, critic_params, batch, batch_size, mjx_model, keys):\n",
    "    # batch_size = batch.states.shape[0]\n",
    "    states = batch.states\n",
    "    # Generate data for simulation\n",
    "    in_data = reset(mjx_model, batch_size).replace(qpos = states[:,0:2], qvel = states[:,2:4])\n",
    "    out_data, keys, exp = jit_v_nn_multi_steps(controller_params, mjx_model, in_data, keys)\n",
    "    out_states = jp.stack([out_data.qpos, out_data.qvel], axis=1).reshape(batch_size,4)\n",
    "    # jax.debug.print(\"out_states shape{0}\", out_states.shape)\n",
    "    critic_score = v_critic(critic_params, out_states)\n",
    "    \n",
    "    loss = -jp.mean(critic_score)\n",
    "    return loss\n",
    "\n",
    "jit_total_loss_grad_value = jax.jit(jax.value_and_grad(total_loss), static_argnames=[\"batch_size\"])\n",
    "\n",
    "# Test total_lose\n",
    "# batch_size = 100\n",
    "# batch = Memory.sample(exp_pool, batch_size, key)\n",
    "# key = jax.random.split(key, 1)[0]\n",
    "# keys = jax.random.split(key,batch_size)\n",
    "# jit_total_loss = jax.jit(total_loss, static_argnames=[\"batch_size\"])\n",
    "# loss, grad = jit_total_loss_grad_value(controller_params, critic_params, batch, batch_size, mjx_model, keys)\n",
    "# print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_params = controller_params\n",
    "for i in range(100):\n",
    "    batch = Memory.sample(exp_pool, batch_size, key)\n",
    "    key = jax.random.split(key, 1)[0]\n",
    "    keys = jax.random.split(key,batch_size)\n",
    "    loss, loss_grad = jit_total_loss_grad_value(new_params, critic_params, batch, batch_size, mjx_model, keys)\n",
    "    print(loss)\n",
    "    # Update params\n",
    "    updates, opt_stats = jit_tx_update(loss_grad, opt_state)\n",
    "    new_params = jit_apply_update(new_params, updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller_params = new_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the controller with the critic net and the differentiable simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short Horizon Gradient calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_shape(x):\n",
    "    # print(x.shape)\n",
    "    return x.reshape(batch_size*fock_size,-1) \n",
    "d = jax.tree.map(change_shape,datas)\n",
    "print(d.qpos.shape)\n",
    "print(datas.qpos.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(keys.shape)\n",
    "kk = jax.vmap(jax.random.split, in_axes=(0,None))(keys, 5)\n",
    "print(kk.shape)\n",
    "k = jp.reshape(kk, jp.array(kk.shape))\n",
    "print(k.shape)\n",
    "\n",
    "[*kk.shape][1:]\n",
    "# print(kk.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn To generate Critic Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas.qpos.shape\n",
    "b = jp.stack([datas.qpos, datas.qvel], axis=1).reshape(datas.qpos.shape[0],-1)\n",
    "print(b[0])\n",
    "print(datas.qpos[0])\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[2,3,4]]\n",
    "b = [6,7]\n",
    "b += a\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jp.stack([datas.qpos, datas.qvel], axis=1).reshape(100,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biomujoco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
