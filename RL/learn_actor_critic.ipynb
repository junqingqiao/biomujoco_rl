{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn Actor Crititc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mediapy as media\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../Biodiffrl\")\n",
    "\n",
    "\n",
    "import os\n",
    "# os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \".60\"\n",
    "\n",
    "# Optionally, force JAX to preallocate memory.\n",
    "# os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"true\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "\n",
    "# Setup environment variable for Nvidia GPU acceleration\n",
    "os.environ['XLA_FLAGS'] = (\n",
    "    '--xla_gpu_triton_gemm_any=True'\n",
    ")\n",
    "backend = 'gpu'\n",
    "# backend = 'METAL'\n",
    "# backend = 'cpu'\n",
    "\n",
    "import jax\n",
    "from jax import numpy as jp\n",
    "\n",
    "import optax\n",
    "\n",
    "\n",
    "# Enable compliation catch\n",
    "jax.config.update(\"jax_compilation_cache_dir\", \"./jax_cache\")\n",
    "jax.config.update(\"jax_persistent_cache_min_entry_size_bytes\", 0)\n",
    "jax.config.update(\"jax_persistent_cache_min_compile_time_secs\", 5)\n",
    "# jax.config.update(\"jax_explain_cache_misses\", True)\n",
    "\n",
    "# Debug Nan\n",
    "jax.config.update(\"jax_debug_nans\", False)\n",
    "\n",
    "\n",
    "# More legible printing from numpy.\n",
    "jp.set_printoptions(precision=4, suppress=True, linewidth=100)\n",
    "\n",
    "import mujoco\n",
    "import mujoco.mjx as mjx\n",
    "from mujoco.mjx._src import scan\n",
    "from mujoco.mjx._src import types\n",
    "\n",
    "# More legible printing from numpy.\n",
    "np.set_printoptions(precision=4, suppress=True, linewidth=100)\n",
    "\n",
    "from IPython.display import clear_output\n",
    "clear_output()\n",
    "\n",
    "device = jax.devices(backend=backend)[0]\n",
    "\n",
    "model_path = '../model/inverted_pendulum.xml'\n",
    "\n",
    "# Single step\n",
    "mjx_step = jax.jit(mjx.step, backend=backend)\n",
    "\n",
    "\n",
    "\n",
    "# mjx_multiple_steps = jax.jit(multiple_steps, backend=backend, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mujoco.mjx._src.biomtu import acceleration_mtu\n",
    "\n",
    "mj_model = mujoco.MjModel.from_xml_path(model_path)\n",
    "mjx_model = mjx.put_model(mj_model,device=device)\n",
    "\n",
    "# Disable tendon\n",
    "opt = mjx_model.opt.replace(disableflags = mjx_model.opt.disableflags |mujoco.mjtDisableBit.mjDSBL_PASSIVE)\n",
    "mjx_model = mjx_model.replace(opt=opt)\n",
    "\n",
    "mjx_data = mjx.make_data(mjx_model)\n",
    "mj_data = mujoco.MjData(mj_model)\n",
    "\n",
    "# Load the Keyframe\n",
    "# mjx_data = mjx_data.replace(qpos = mj_model.key_qpos[0])\n",
    "# mj_data.qpos = mj_model.key_qpos[0]\n",
    "\n",
    "# Calculate equilibrum\n",
    "# mjx_data = acceleration_mtu.calc_equilibrium(mjx_model, mjx_data)\n",
    "mjx_data = mjx_step(mjx_model, mjx_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control Neural Network and Critic Neural Network\n",
    "For now this NN will only work for the inverted pendulum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nn\n",
    "\n",
    "key = jax.random.key(2024)\n",
    "# Controller NN\n",
    "controller_nn = nn.Controller_NN(mjx_model.nq*2, 1)\n",
    "controller_params, key = controller_nn.init_parameters(key)\n",
    "controller = controller_nn.get_fn()\n",
    "\n",
    "# Critic NN\n",
    "critic_nn = nn.Critic_NN(mjx_model.nq*2,1)\n",
    "critic_params, key = critic_nn.init_parameters(key)\n",
    "criticer = critic_nn.get_fn()\n",
    "\n",
    "# Test the two neural networks\n",
    "print(controller(controller_params, jp.ones(mjx_model.nq*2), key))\n",
    "print(criticer(critic_params, jp.ones(mjx_model.nq*2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Control "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @jax.jit\n",
    "def reset(model, batch_size):\n",
    "    batch_dummy = jp.zeros(batch_size)\n",
    "    v_make_data = jax.jit(jax.vmap(lambda model, batch_dummy: mjx.make_data(model), in_axes=(None,0),out_axes=0))\n",
    "    new_datas = v_make_data(model, batch_dummy)\n",
    "    return new_datas\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-steps forward simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import exp\n",
    "\n",
    "def step_fn(carry, _):\n",
    "    data, model = carry\n",
    "    new_data = mjx.step(model, data)\n",
    "    new_carry = (new_data, model)\n",
    "    return new_carry, _\n",
    "\n",
    "def multiple_steps(model, data):\n",
    "    init_carry = (data, model)\n",
    "    y, _ = jax.lax.scan(step_fn, init_carry, None, length=10)\n",
    "    new_data = y[0]\n",
    "    return new_data\n",
    "\n",
    "def nn_mjx_one_step(nn_params, model, data, key):\n",
    "    states = jp.concatenate([data.qpos, data.qvel])\n",
    "    act, mean, std = controller(nn_params, states, key)\n",
    "    # Generate the next key\n",
    "    new_key = jax.random.split(key,1)[0]\n",
    "    data = data.replace(ctrl = jp.array(act))\n",
    "    new_data = mjx.step(model, data)\n",
    "    return new_data, new_key, act\n",
    "\n",
    "@jax.jit\n",
    "def jit_nn_mjx_one_step_no_random(nn_params, model, data, key):\n",
    "    states = jp.concatenate([data.qpos, data.qvel])\n",
    "    act, mean, std = controller(nn_params, states, key)\n",
    "    # Generate the next key\n",
    "    new_key = jax.random.split(key,1)[0]\n",
    "    data = data.replace(ctrl = jp.array(mean))\n",
    "    new_data = mjx.step(model, data)\n",
    "    return new_data, new_key, mean\n",
    "\n",
    "def nn_step_fn(carry, _):\n",
    "    nn_params, model, data, key = carry\n",
    "    new_data, new_key, act = nn_mjx_one_step(nn_params, model, data, key)\n",
    "    new_carry = (nn_params, model, new_data, new_key)\n",
    "    # Calculate reward\n",
    "    state = jp.stack([data.qpos, data.qvel], axis=0).flatten()\n",
    "    next_state = jp.stack([new_data.qpos, data.qvel], axis=0).flatten()\n",
    "    action = act\n",
    "    reward = -jp.abs(new_data.qpos[1])\n",
    "    done = jp.abs(data.qpos[1])>0.5\n",
    "    experience = exp.experience(state, next_state, action, reward, done)\n",
    "    \n",
    "    return new_carry, experience\n",
    "\n",
    "def decay_sum_scan(x, decay):\n",
    "    def f(sxtm1, xt):\n",
    "        b = xt + decay * sxtm1\n",
    "        return b, b\n",
    "    return jax.lax.scan(f, jp.zeros(x.shape[1:]), x)[1]\n",
    "\n",
    "@jax.jit\n",
    "def jit_nn_multi_steps(nn_params, model, data, key):\n",
    "    repeat_length = 10\n",
    "    init_carry = (nn_params, model, data, key)\n",
    "    y, experience = jax.lax.scan(nn_step_fn, init_carry, None, length=repeat_length)\n",
    "    new_data = y[2]\n",
    "    new_key = y[3]\n",
    "    \n",
    "    return new_data, new_key, experience\n",
    "\n",
    "@jax.jit\n",
    "def jit_v_nn_multi_steps(nn_params, model, data, key):\n",
    "    return jax.vmap(jit_nn_multi_steps, in_axes=(None, None, 0, 0))(nn_params, model, data, key)\n",
    "\n",
    "# This function generate\n",
    "@jax.jit\n",
    "def jit_vv_nn_multi_steps(nn_params, model, data, key):\n",
    "    return jax.vmap(jit_v_nn_multi_steps, in_axes=(None, None, None, 1))(nn_params, model, data, key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the critic loss and at the same time generate experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "import exp\n",
    "\n",
    "critic_batch_size = 400\n",
    "controller_batch_size = 400\n",
    "key = jax.random.key(2024)\n",
    "keys = jax.random.split(key, critic_batch_size)\n",
    "datas = reset(mjx_model,critic_batch_size)\n",
    "\n",
    "memory_settings = exp.memory_settings(critic_batch_size*5*40, 4, 1, 1)\n",
    "exp_pool = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate initial experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = reset(mjx_model,critic_batch_size)\n",
    "for i in range(10):    # For 2 seconds\n",
    "    datas, keys, exps = jit_v_nn_multi_steps(controller_params, mjx_model, datas, keys)\n",
    "    # print(datas.qvel.shape, datas.ten_J.shape)\n",
    "    exp_pool = exp.memory.add_exp(memory_settings, exp_pool, exps)\n",
    "    \n",
    "#plot exp_pool\n",
    "plt.plot(exp_pool.states.T[1])\n",
    "plt.plot(exp_pool.rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to calculate the criticer's gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_criticer = jax.vmap(criticer,in_axes=(None, 0))\n",
    "\n",
    "def critic_loss(params, batch):\n",
    "    discount = 0.95\n",
    "    states = batch.states\n",
    "    next_states = batch.next_states\n",
    "    actions = batch.actions\n",
    "    rewards = batch.rewards\n",
    "    \n",
    "    critic_score = v_criticer(params, states)\n",
    "    target = rewards + discount* jax.lax.stop_gradient(v_criticer(params, next_states))\n",
    "    \n",
    "    loss = optax.l2_loss(critic_score, target)\n",
    "    loss = jp.mean(loss)\n",
    "    return loss\n",
    "\n",
    "sample_batch = exp.memory.sample(exp_pool, critic_batch_size, key)\n",
    "critic_loss_g_value_lower= jax.jit(jax.value_and_grad(critic_loss)).lower(critic_params, sample_batch)\n",
    "\n",
    "jit_critic_loss_g_value = critic_loss_g_value_lower.compile()\n",
    "a=jit_critic_loss_g_value.cost_analysis()[0]['flops']\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to get controller gradient and generate experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def controller_loss_and_experience(controller_params, critic_params, states, batch_size, mjx_model, keys):\n",
    "    # Generate data for simulation\n",
    "    in_data = reset(mjx_model, batch_size).replace(qpos = states[:,0:2], qvel = states[:,2:4])\n",
    "    out_data, keys, new_exps = jit_v_nn_multi_steps(controller_params, mjx_model, in_data, keys)\n",
    "    out_states = jp.stack([out_data.qpos, out_data.qvel], axis=1).reshape(batch_size,4)\n",
    "    # jax.debug.print(\"out_states shape{0}\", out_states.shape)\n",
    "    critic_score = v_criticer(critic_params, out_states)\n",
    "    \n",
    "    loss = -jp.mean(critic_score)\n",
    "    return loss, new_exps\n",
    "\n",
    "# The function calculating the loss of the controller and also generate experiences\n",
    "g_loss_experience = jax.value_and_grad(controller_loss_and_experience, has_aux=True)\n",
    "\n",
    "controller_keys = jax.random.split(key, controller_batch_size)\n",
    "sample_batch = exp.memory.sample(exp_pool, controller_batch_size, key)\n",
    "g_loss_experience_lower = jax.jit(g_loss_experience, static_argnames=[\"batch_size\"]).lower(controller_params, critic_params, sample_batch.states, controller_batch_size, mjx_model, controller_keys)\n",
    "jit_g_loss_experience = g_loss_experience_lower.compile()\n",
    "\n",
    "b = jit_g_loss_experience.cost_analysis()[0]['flops']\n",
    "print(b)\n",
    "# exp_pool = exp.memory.add_exp(memory_settings, exp_pool, exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample_batch.states.shape)\n",
    "\n",
    "b/a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the two neural networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic_params, key = critic_nn.init_parameters(key)\n",
    "critic_tx = optax.apply_if_finite(optax.adam(learning_rate=5e-5), max_consecutive_errors=20)\n",
    "critic_opt_state = critic_tx.init(critic_params)\n",
    "jit_critic_tx_update = jax.jit(critic_tx.update)\n",
    "\n",
    "\n",
    "controller_params, key = controller_nn.init_parameters(key)\n",
    "controller_tx = optax.apply_if_finite(optax.adam(learning_rate=5e-5), max_consecutive_errors=20)\n",
    "controller_opt_state = controller_tx.init(controller_params)\n",
    "jit_controller_tx_update = jax.jit(controller_tx.update)\n",
    "\n",
    "jit_apply_update = jax.jit(optax.apply_updates)\n",
    "\n",
    "# Init exp_pool\n",
    "exp_pool = None\n",
    "datas = reset(mjx_model,critic_batch_size)\n",
    "for i in range(10):    # For 2 seconds\n",
    "    datas, keys, exps = jit_v_nn_multi_steps(controller_params, mjx_model, datas, keys)\n",
    "    # print(datas.qvel.shape, datas.ten_J.shape)\n",
    "    exp_pool = exp.memory.add_exp(memory_settings, exp_pool, exps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import exp\n",
    "\n",
    "key = jax.random.key(241)\n",
    "\n",
    "for i in range(2000):\n",
    "\n",
    "    print(\"----------\",i,\"----------\")\n",
    "    batch = exp.memory.sample(exp_pool, critic_batch_size, key)\n",
    "    key = jax.random.split(key, 1)[0]\n",
    "    \n",
    "    # criticer\n",
    "    critic_loss, critic_loss_grad = jit_critic_loss_g_value(critic_params, batch)\n",
    "    print(\"criticer loss:\",critic_loss)\n",
    "    \n",
    "    # Update params\n",
    "    critic_updates, critic_opt_state = jit_critic_tx_update(critic_loss_grad, critic_opt_state)\n",
    "    critic_params = jit_apply_update(critic_params, critic_updates)\n",
    "    \n",
    "    # controller\n",
    "    \n",
    "    # for j in range(3):\n",
    "    keys = jax.random.split(key,controller_batch_size)\n",
    "    states = jp.vstack([exp.memory.sample(exp_pool, int(controller_batch_size/50*45), key).states, \n",
    "                        jax.random.normal(key,(int(controller_batch_size/50*5),4))/10])\n",
    "    key = jax.random.split(key, 1)[0]\n",
    "    controller_loss_exps, controller_loss_grad = jit_g_loss_experience(controller_params, critic_params, states, mjx_model, keys)\n",
    "    controller_loss = controller_loss_exps[0]\n",
    "    exps = controller_loss_exps[1]\n",
    "    print(\"Controller Loss:\", controller_loss)\n",
    "        \n",
    "    # Update params\n",
    "    controller_updates, controller_opt_state = jit_controller_tx_update(controller_loss_grad, controller_opt_state)\n",
    "    controller_params = jit_apply_update(controller_params, controller_updates)\n",
    "    \n",
    "    # add exps\n",
    "    exp_pool = exp.memory.add_exp(memory_settings, exp_pool, exps)\n",
    "    \n",
    "    if(i%20 == 0):\n",
    "        plt.figure()\n",
    "        plt.plot(exp_pool.states.T[1])\n",
    "        plt.plot(exp_pool.rewards)\n",
    "    \n",
    "    # Remove done from exp_pool\n",
    "    exp_pool = exp.memory.remove_done(exp_pool)\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "    # if(i%3 ==0):\n",
    "    #     datas = reset(mjx_model,ciritc_batch_size)\n",
    "    #     for i in range(5):    # For 2 seconds\n",
    "    #         datas, keys, exps = jit_v_nn_multi_steps(controller_params, mjx_model, datas, keys)\n",
    "    #         exp_pool = exp.memory.add_exp(memory_settings, exp_pool, exps)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = reset(mjx_model,controller_batch_size)\n",
    "keyss = jax.random.split(key,100)\n",
    "jax.random.normal(key,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the model and controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mujoco.viewer\n",
    "import time\n",
    "\n",
    "\n",
    "mjx_data = mjx.make_data(mjx_model)\n",
    "mj_data = mujoco.MjData(mj_model)\n",
    "previous_frame_time = time.time()\n",
    "i = 0\n",
    "key = jax.random.key(334)\n",
    "with mujoco.viewer.launch_passive(mj_model, mj_data) as viewer:\n",
    "    while viewer.is_running():\n",
    "        # Update mjx_data from mj_data. The mj_data was modified by the viewer\n",
    "        # mjx_data = mjx_data.replace(ctrl=mj_data.ctrl, xfrc_applied=mj_data.xfrc_applied)\n",
    "        # Use the nerual network to generate ctrl signal\n",
    "        # Generate key\n",
    "        mjx_data = mjx_data.replace(xfrc_applied=jp.array(mj_data.xfrc_applied, dtype=jp.float32))\n",
    "        mjx_data = mjx_data.replace(\n",
    "            qpos= jp.array(mj_data.qpos, dtype=jp.float32),\n",
    "            qvel= jp.array(mj_data.qvel, dtype=jp.float32),\n",
    "            time = jp.array(mj_data.time, dtype=jp.float32))\n",
    "        \n",
    "        # Update mjx_model from mj_model\n",
    "        mjx_model = mjx_model.tree_replace({\n",
    "            'opt.gravity': jp.array(mj_model.opt.gravity, dtype=jp.float32),\n",
    "            'opt.tolerance': jp.array(mj_model.opt.tolerance, dtype=jp.float32),\n",
    "            'opt.ls_tolerance': jp.array(mj_model.opt.ls_tolerance, dtype=jp.float32),\n",
    "            'opt.timestep': jp.array(mj_model.opt.timestep, dtype=jp.float32),\n",
    "        })\n",
    "        \n",
    "        key = jax.random.split(key,1)[0]\n",
    "        # mjx_data = mjx_step(mjx_model, mjx_data)\n",
    "        # mjx_data, loss, exps = jit_nn_multi_steps(controller_params, mjx_model, mjx_data, key)\n",
    "        mjx_data, key, act = jit_nn_mjx_one_step_no_random(controller_params, mjx_model, mjx_data, key)\n",
    "        mjx.get_data_into(mj_data, mj_model, mjx_data)\n",
    "        \n",
    "        # Record the current time at the start of this frame\n",
    "        current_frame_time = time.time()\n",
    "    \n",
    "        # Calculate the difference in time from the last frame\n",
    "        time_between_frames = current_frame_time - previous_frame_time\n",
    "    \n",
    "        # Print the time between frames\n",
    "        print(f\"Time between frames: {time_between_frames} seconds\")\n",
    "        previous_frame_time = current_frame_time\n",
    "        \n",
    "        # print(\"ACT:\", mjx_data.biomtu.act)\n",
    "        print(mjx_data.qpos)\n",
    "        # print(mjx_data.sensordata)\n",
    "        # print(len(mjx_data.qvel))\n",
    "        viewer.sync()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_pool.states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keeps = ~jp.concat(exp_pool.dones)\n",
    "print(keeps)\n",
    "new_pool = jax.tree.map(lambda x: jp.compress(keeps, x, axis=0), exp_pool)\n",
    "print(new_pool.dones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pool2 = exp.memory.remove_done(exp_pool)\n",
    "print(jp.count_nonzero(jp.abs(exp_pool.states[:,1])>1))\n",
    "print(test_pool2.dones.shape)\n",
    "print(exp_pool.dones.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jp.concat(exp_pool.rewards)>1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(exp_pool.states.T[1])\n",
    "plt.plot(exp_pool.rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biomujoco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
