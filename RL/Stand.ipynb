{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RL code to teach the model to stand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup jax enviroment and Load Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mediapy as media\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../Biodiffrl\")\n",
    "\n",
    "import os\n",
    "# os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \".60\"\n",
    "\n",
    "# Optionally, force JAX to preallocate memory.\n",
    "# os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"true\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "\n",
    "# Setup environment variable for Nvidia GPU acceleration\n",
    "os.environ['XLA_FLAGS'] = (\n",
    "    # '--xla_gpu_enable_triton_softmax_fusion=true '\n",
    "    '--xla_gpu_triton_gemm_any=True '\n",
    "    # '--xla_gpu_enable_async_collectives=true '\n",
    "    # '--xla_gpu_enable_latency_hiding_scheduler=true '\n",
    "    '--xla_gpu_enable_highest_priority_async_stream=true '\n",
    "    # '--xla_cpu_multi_thread_eigen=true intra_op_parallelism_threads=32'\n",
    ")\n",
    "\n",
    "backend = 'gpu'\n",
    "# backend = 'METAL'\n",
    "# backend = 'cpu'\n",
    "\n",
    "import jax\n",
    "jax.config.update('jax_platform_name', 'gpu')\n",
    "os.environ[\"TF_XLA_FLAGS\"] = \"--tf_xla_enable_lazy_compilation=false\"\n",
    "# Enable compliation catch\n",
    "os.environ[\"JAX_COMPILATION_CACHE_DIR\"] = \"./jax_cache\"\n",
    "jax.config.update(\"jax_compilation_cache_dir\", \"./jax_cache\")\n",
    "jax.config.update(\"jax_persistent_cache_min_entry_size_bytes\", 0)\n",
    "jax.config.update(\"jax_persistent_cache_min_compile_time_secs\", 2)\n",
    "# jax.config.update(\"jax_explain_cache_misses\", True)\n",
    "\n",
    "from jax.experimental.compilation_cache import compilation_cache as cc\n",
    "cc.set_cache_dir(\"./jax_cache\")\n",
    "# Debug Nan\n",
    "# jax.config.update(\"jax_debug_nans\", True)\n",
    "\n",
    "from jax import numpy as jp\n",
    "# More legible printing from numpy.\n",
    "jp.set_printoptions(precision=4, suppress=True, linewidth=100)\n",
    "\n",
    "import mujoco\n",
    "import mujoco.mjx as mjx\n",
    "from mujoco.mjx._src import scan\n",
    "from mujoco.mjx._src import types\n",
    "\n",
    "# More legible printing from numpy.\n",
    "np.set_printoptions(precision=4, suppress=True, linewidth=100)\n",
    "\n",
    "from IPython.display import clear_output\n",
    "clear_output()\n",
    "\n",
    "device = jax.devices(backend=backend)[0]\n",
    "\n",
    "model_path = '/home/bugman/Currentwork/biomujoco_converter/converted/mjc/Gait2354/gait2354_cvt1.xml'\n",
    "\n",
    "# Single step\n",
    "mjx_step = jax.jit(mjx.step, backend=backend)\n",
    "\n",
    "\n",
    "\n",
    "# mjx_multiple_steps = jax.jit(multiple_steps, backend=backend, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mujoco.mjx._src.biomtu import acceleration_mtu\n",
    "\n",
    "mj_model = mujoco.MjModel.from_xml_path(model_path)\n",
    "mjx_model = mjx.put_model(mj_model,device=device)\n",
    "\n",
    "# Disable tendon\n",
    "opt = mjx_model.opt.replace(disableflags = mjx_model.opt.disableflags |mujoco.mjtDisableBit.mjDSBL_PASSIVE)\n",
    "mjx_model = mjx_model.replace(opt=opt)\n",
    "\n",
    "mjx_data = mjx.make_data(mjx_model)\n",
    "mj_data = mujoco.MjData(mj_model)\n",
    "\n",
    "# Load the Keyframe\n",
    "mjx_data = mjx_data.replace(qpos = mj_model.key_qpos[0])\n",
    "mj_data.qpos = mj_model.key_qpos[0]\n",
    "\n",
    "# Calculate equilibrum\n",
    "mjx_data = acceleration_mtu.calc_equilibrium(mjx_model, mjx_data)\n",
    "mjx_data = jax.jit(mjx_step)(mjx_model, mjx_data)\n",
    "\n",
    "init_mjx_data = mjx_data\n",
    "\n",
    "def print_all():\n",
    "    print(mjx_model.biomtu_adr)\n",
    "    print(mjx_model.mtu_wrap_objid)\n",
    "    print(mjx_model.mtu_wrap_type)\n",
    "    print(mjx_model.biomtu_fiso)\n",
    "    print(mjx_model.biomtu_vmax)\n",
    "    print(mjx_model.biomtu_ofl)\n",
    "    print(mjx_model.biomtu_opa)\n",
    "    print(mjx_model.biomtu_mass)\n",
    "    print(\"-------Data--------\")\n",
    "    print(\"qpos:\", mjx_data.qpos)\n",
    "    print(\"mtu l:\", mjx_data.biomtu.l)\n",
    "    print(\"tendon l:\", mjx_data.biomtu.tendon_l)\n",
    "    print(\"fiber l :\", mjx_data.biomtu.fiber_l)\n",
    "    print(\"Muscle Bce:\", mjx_data.biomtu.B_ce)\n",
    "    print(\"Muscle vm:\", mjx_data.biomtu.m)\n",
    "    print(\"Fiber acc:\", mjx_data.biomtu.fiber_acc)\n",
    "    print(\"Fiber v:\", mjx_data.biomtu.fiber_v)\n",
    "    print(\"Biomtu h:\", mjx_data.biomtu.h)\n",
    "    print(mjx_data.biomtu.v)\n",
    "    print(mjx_data.biomtu.h)  # The constant high of the muscle.\n",
    "    print(mjx_data.biomtu.pennation_angle)\n",
    "    print(mjx_data.biomtu.origin_body_id)\n",
    "    print(mjx_data.biomtu.insertion_body_id)\n",
    "    print(\"mtu act:\", mjx_data.biomtu.act)\n",
    "    # print(mjx_data.biomtu.j)\n",
    "    print(mjx_data.qfrc_biomtu)\n",
    "    print(mj_model.key_time)\n",
    "    print(mj_model.key_qpos)\n",
    "    print(mj_model.key_qvel)\n",
    "\n",
    "# print_all()\n",
    "\n",
    "print(mjx_model.nbiomtu)\n",
    "print(mjx_model.nq)\n",
    "print(mjx_data.qpos)\n",
    "print(mjx_data.qvel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nn\n",
    "\n",
    "key = jax.random.key(2024)\n",
    "# Controller NN\n",
    "controller_nn = nn.Controller_NN(mjx_model.nq*2+mjx_model.nbiomtu*2, mjx_model.nbiomtu)\n",
    "controller_params, key = controller_nn.init_parameters(key)\n",
    "controller = controller_nn.get_fn()\n",
    "\n",
    "# Critic NN\n",
    "critic_nn = nn.Critic_NN(mjx_model.nq*2 + mjx_model.nbiomtu*2,1)\n",
    "critic_params, key = critic_nn.init_parameters(key)\n",
    "criticer = critic_nn.get_fn()\n",
    "\n",
    "# Test the two neural networks\n",
    "controller_output = controller(controller_params, jp.ones(mjx_model.nq*2+mjx_model.nbiomtu*2), key)\n",
    "print(controller_output[0].shape)\n",
    "print(controller_output)\n",
    "print(criticer(critic_params, jp.ones(mjx_model.nq*2+mjx_model.nbiomtu*2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "# Since the environment resets with init_mjx_data, the muscles are already in the equilibrum condition.\n",
    "def reset(init_mjx_data, batch_size):\n",
    "    new_data = jax.tree.map(\n",
    "        partial(jp.repeat, repeats=batch_size, axis=0),\n",
    "        jax.tree.map(partial(jp.expand_dims, axis=0),init_mjx_data))\n",
    "    return new_data\n",
    "\n",
    "def random_init(data, model, rng: jax.Array):\n",
    "    nbiomtu = model.nq\n",
    "    init_qpos = data.qpos\n",
    "    init_qvel = data.qvel\n",
    "    new_rng, rng1, rng2 = jax.random.split(rng, 3)\n",
    "    # Qpos_1 is the vertical position\n",
    "    random_qpos = init_qpos + jax.random.uniform(rng1, [nbiomtu], minval=jp.array(-1.0, dtype=jp.float32), maxval=jp.array(1.0, dtype=jp.float32))*0.01\n",
    "    random_qvel = init_qvel + jax.random.uniform(rng2, [nbiomtu], minval=jp.array(-1.0, dtype=jp.float32), maxval=jp.array(1.0, dtype=jp.float32))*0.01\n",
    "    newdata = data.replace(qpos=random_qpos)\n",
    "    newdata = newdata.replace(qvel=random_qvel)\n",
    "    newdata = mjx.forward(mjx_model, newdata)\n",
    "    # print('data:',data.qpos, data.qvel)\n",
    "    # Calculate equilibrum\n",
    "    # newdata = acceleration_mtu.calc_equilibrium(mjx_model, newdata)\n",
    "    # newdata = mjx_step(mjx_model, newdata)\n",
    "    return newdata, new_rng\n",
    "\n",
    "vrandom_init = jax.jit(jax.vmap(random_init, in_axes=(None, None, 0), out_axes=0))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-steps forward simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import exp\n",
    "\n",
    "# Multiple steps\n",
    "def step_fn(carry, _):\n",
    "    model, data= carry\n",
    "    new_data = mjx.step(model, data)\n",
    "    new_carry = (model, new_data)\n",
    "    return new_carry, _\n",
    "\n",
    "def multiple_steps(model, data):\n",
    "    init_carry = (model, data)\n",
    "    y, _ = jax.lax.scan(step_fn, init_carry, None, length=10)\n",
    "    new_data = y[0]\n",
    "    return new_data\n",
    "\n",
    "# For one step\n",
    "def nn_mjx_one_step(nn_params, model, data, key):\n",
    "    states = jp.concatenate([data.qpos, data.qvel, data.biomtu.fiber_l, data.biomtu.fiber_v])\n",
    "    act, mean, std = controller(nn_params, states, key)\n",
    "    # Generate the next key\n",
    "    new_key = jax.random.split(key,1)[0]\n",
    "    data = data.replace(biomtu = data.biomtu.replace(act = act))\n",
    "    new_data = mjx.step(model, data)\n",
    "    return new_data, new_key, act\n",
    "\n",
    "def nn_mjx_perturbe_one_step(nn_params, model, data, key):\n",
    "    states = jp.concatenate([data.qpos, data.qvel, data.biomtu.fiber_l, data.biomtu.fiber_v])\n",
    "    act, mean, std = controller(nn_params, states, key)\n",
    "    # Generate the next key\n",
    "    new_key = jax.random.split(key,1)[0]\n",
    "    data = data.replace(biomtu = data.biomtu.replace(act = act))\n",
    "    xfrc = jax.random.normal(key,(mjx_model.nbody, 6))*1.0\n",
    "    data = data.replace(xfrc_applied=xfrc)\n",
    "    new_data = mjx.step(model, data)\n",
    "    return new_data, new_key, act\n",
    "\n",
    "@jax.jit\n",
    "def jit_nn_mjx_one_step_no_random(nn_params, model, data, key):\n",
    "    states = jp.concatenate([data.qpos, data.qvel, data.biomtu.fiber_l, data.biomtu.fiber_v])\n",
    "    act, mean, std = controller(nn_params, states, key)\n",
    "    # Generate the next key\n",
    "    new_key = jax.random.split(key,1)[0]\n",
    "    data = data.replace(biomtu = data.biomtu.replace(act = act))\n",
    "    new_data = mjx.step(model, data)\n",
    "    return new_data, new_key, mean\n",
    "\n",
    "def nn_step_fn(carry, _):\n",
    "    nn_params, model, data, key = carry\n",
    "    new_data, new_key, act = nn_mjx_one_step(nn_params, model, data, key)\n",
    "    # new_data, new_key, act = nn_mjx_perturbe_one_step(nn_params, model, data, key)\n",
    "    new_carry = (nn_params, model, new_data, new_key)\n",
    "    # Calculate reward\n",
    "    head_height = new_data.sensordata[2]\n",
    "    state = jp.concat([data.qpos, data.qvel, data.biomtu.fiber_l, data.biomtu.fiber_v])\n",
    "    next_state = jp.concat([new_data.qpos, new_data.qvel, new_data.biomtu.fiber_l, new_data.biomtu.fiber_v])\n",
    "    action = act\n",
    "    # done = head_hight < 1.2\n",
    "    done = jp.where(head_height <= 1, jp.float32(1), jp.float32(0))\n",
    "    reward = -(head_height-1.63)**2 - done*0.5\n",
    "    experience = exp.experience(state, next_state, action, reward, done)\n",
    "    \n",
    "    return new_carry, experience\n",
    "\n",
    "@jax.jit\n",
    "def nn_multi_steps(nn_params, model, data, key):\n",
    "    # Also deal with the done in the experience pool\n",
    "    \n",
    "    repeat_length = 50  # Simulate for 0.1s\n",
    "    init_carry = (nn_params, model, data, key)\n",
    "    y, experience = jax.lax.scan(nn_step_fn, init_carry, None, length=repeat_length)\n",
    "    new_data = y[2]\n",
    "    new_key = y[3]\n",
    "    return new_data, new_key, experience\n",
    "\n",
    "jit_nn_multi_steps = jax.jit(nn_multi_steps)\n",
    "\n",
    "# @jax.jit\n",
    "def v_nn_multi_steps(nn_params, model, data, keys):\n",
    "    return jax.vmap(nn_multi_steps, in_axes=(None, None, 0, 0))(nn_params, model, data, keys)\n",
    "\n",
    "jit_v_nn_multi_steps = jax.jit(v_nn_multi_steps)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "import exp\n",
    "\n",
    "critic_batch_size = 64*10\n",
    "controller_batch_size = 64\n",
    "key = jax.random.key(2024)\n",
    "keys = jax.random.split(key, controller_batch_size)\n",
    "\n",
    "memory_settings = exp.memory_settings(critic_batch_size*126, mjx_model.nq*2+mjx_model.nbiomtu*2, mjx_model.nbiomtu, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate initial experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_pool = None\n",
    "datas = jax.jit(reset,static_argnames=\"batch_size\")(init_mjx_data, controller_batch_size)\n",
    "init_data_batch = datas\n",
    "for i in range(5):\n",
    "    datas, keys, exps = jit_v_nn_multi_steps(controller_params, mjx_model, datas, keys)\n",
    "    # print(datas.qvel.shape, datas.ten_J.shape)\n",
    "    exp_pool = exp.memory.add_exp(memory_settings, exp_pool, exps)\n",
    "    \n",
    "print(exp_pool.states.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Critic gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "\n",
    "v_criticer = jax.vmap(criticer,in_axes=(None, 0))\n",
    "jit_v_criticer = jax.jit(v_criticer)\n",
    "\n",
    "def critic_loss(params, batch):\n",
    "    discount = 0.995\n",
    "    states = batch.states\n",
    "    next_states = batch.next_states\n",
    "    actions = batch.actions\n",
    "    rewards = batch.rewards\n",
    "    \n",
    "    critic_score = v_criticer(params, states)\n",
    "    # target = rewards + discount* jax.lax.stop_gradient(v_criticer(params, next_states))\n",
    "    target = rewards + discount* (v_criticer(params, next_states))\n",
    "    \n",
    "    loss = optax.l2_loss(critic_score, target)\n",
    "    loss = jp.mean(loss)\n",
    "    return loss\n",
    "\n",
    "sample_batch = exp.memory.sample(exp_pool, critic_batch_size, key)\n",
    "critic_loss_g_value_lower= jax.jit(jax.value_and_grad(critic_loss)).lower(critic_params, sample_batch)\n",
    "\n",
    "jit_critic_loss_g_value = critic_loss_g_value_lower.compile()\n",
    "a=jit_critic_loss_g_value.cost_analysis()[0]['flops']\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Actor gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def controller_loss_and_experience(controller_params, critic_params, batch, batch_size, mjx_model, init_data_batch, keys):\n",
    "    # Generate data for simulation\n",
    "    nq = mjx_model.nq\n",
    "    nmtu = mjx_model.nbiomtu\n",
    "    \n",
    "    # Deal with the done state, reset the done state with init state\n",
    "    # exp_data_batch = init_data_batch.replace(\n",
    "    #     qpos = batch.states[:,0:nq], \n",
    "    #     qvel = batch.states[:,nq:nq*2],\n",
    "    #     biomtu = init_data_batch.biomtu.replace(\n",
    "    #         fiber_l = batch.states[nq*2, nq*2+nmtu],\n",
    "    #         fiber_v = batch.states[nq*2+nmtu, nq*2+nmtu*2]\n",
    "    #     ))\n",
    "    \n",
    "    qpos = jp.where(batch.dones, init_data_batch.qpos, batch.states[:,0:nq])\n",
    "    qvel = jp.where(batch.dones, init_data_batch.qvel, batch.states[:,nq:nq*2])\n",
    "    fiber_l = jp.where(batch.dones, init_data_batch.biomtu.fiber_l, batch.states[:,nq*2 : nq*2+nmtu])\n",
    "    fiber_v = jp.where(batch.dones, init_data_batch.biomtu.fiber_v, batch.states[:,nq*2+nmtu : nq*2+nmtu*2])\n",
    "    \n",
    "    # in_data = batch.dones, init_data_batch, exp_data_batch)\n",
    "    \n",
    "    in_data = jax.lax.stop_gradient(init_data_batch.replace(\n",
    "        qpos = qpos,\n",
    "        qvel = qvel,\n",
    "        biomtu = init_data_batch.biomtu.replace(\n",
    "            fiber_l = fiber_l,\n",
    "            fiber_v = fiber_v)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    out_data, keys, new_exps = v_nn_multi_steps(controller_params, mjx_model, in_data, keys)\n",
    "    # out_states = jp.concat([out_data.qpos, out_data.qvel],axis=1).reshape(batch_size,4)\n",
    "    # out_states = new_exps.next_states\n",
    "    # jax.debug.print(\"out_states shape{0}\", out_states.shape)\n",
    "    out_states = jp.concat([out_data.qpos, out_data.qvel, out_data.biomtu.fiber_l, out_data.biomtu.fiber_v],axis=1)\n",
    "    critic_score = v_criticer(critic_params, out_states)\n",
    "    \n",
    "    loss = -jp.mean(critic_score)\n",
    "    return loss, new_exps\n",
    "\n",
    "# The function calculating the loss of the controller and also generate experiences\n",
    "g_loss_experience = jax.value_and_grad(controller_loss_and_experience, has_aux=True)\n",
    "\n",
    "controller_keys = jax.random.split(key, controller_batch_size)\n",
    "sample_batch = exp.memory.sample(exp_pool, controller_batch_size, key)\n",
    "\n",
    "print(\"lowering\")\n",
    "g_loss_experience_lower = jax.jit(g_loss_experience, static_argnames=[\"batch_size\"]).lower(\n",
    "    controller_params, \n",
    "    critic_params, \n",
    "    sample_batch, \n",
    "    controller_batch_size, \n",
    "    mjx_model, \n",
    "    init_data_batch, \n",
    "    controller_keys)\n",
    "\n",
    "print(\"compiling\")\n",
    "jit_g_loss_experience = g_loss_experience_lower.compile()\n",
    "\n",
    "b = jit_g_loss_experience.cost_analysis()[0]['flops']\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample_batch.states.shape)\n",
    "print(b/a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the two neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.key(9346)\n",
    "keys = jax.random.split(key, controller_batch_size)\n",
    "\n",
    "critic_params, key = critic_nn.init_parameters(key)\n",
    "critic_tx = optax.apply_if_finite(optax.adam(learning_rate=1e-5), max_consecutive_errors=50)\n",
    "# critic_tx = optax.apply_if_finite(optax.sgd(learning_rate=1e-4), max_consecutive_errors=50)\n",
    "critic_opt_state = critic_tx.init(critic_params)\n",
    "jit_critic_tx_update = jax.jit(critic_tx.update)\n",
    "\n",
    "\n",
    "controller_params, key = controller_nn.init_parameters(key)\n",
    "controller_tx = optax.apply_if_finite(optax.adam(learning_rate=1e-5), max_consecutive_errors=50)\n",
    "# controller_tx = optax.apply_if_finite(optax.sgd(learning_rate=1e-4), max_consecutive_errors=50)\n",
    "controller_opt_state = controller_tx.init(controller_params)\n",
    "jit_controller_tx_update = jax.jit(controller_tx.update)\n",
    "\n",
    "jit_apply_update = jax.jit(optax.apply_updates)\n",
    "\n",
    "\n",
    "jit_sample = jax.jit(exp.memory.sample, static_argnames=\"batch_size\")\n",
    "jit_add_exp = jax.jit(exp.memory.add_exp, static_argnames=\"settings\")\n",
    "\n",
    "# Init exp_pool\n",
    "exp_pool = None\n",
    "datas = reset(init_mjx_data,controller_batch_size)\n",
    "for i in range(6):\n",
    "    datas, keys, exps = jit_v_nn_multi_steps(controller_params, mjx_model, datas, keys)\n",
    "    # print(datas.qvel.shape, datas.ten_J.shape)\n",
    "    if(i>2):\n",
    "        exp_pool = exp.memory.add_exp(memory_settings, exp_pool, exps)\n",
    "\n",
    "#plot exp_pool\n",
    "# plt.plot(exp_pool.states.T[1])\n",
    "plt.plot(exp_pool.rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug Nan\n",
    "# jax.config.update(\"jax_debug_nans\", True)\n",
    "\n",
    "import exp\n",
    "\n",
    "\n",
    "death_rate_buf = []\n",
    "best_death_rate = 0.5\n",
    "\n",
    "for i in range(4000):\n",
    "\n",
    "    print(\"----------\",i,\"----------\")\n",
    "    \n",
    "    criric_repeat = 16\n",
    "    if(i == 500):\n",
    "        criric_repeat = 1\n",
    "        \n",
    "    for j in range(criric_repeat):\n",
    "        batch = jit_sample(exp_pool, critic_batch_size, key)\n",
    "        key = jax.random.split(key, 1)[0]\n",
    "        \n",
    "        # criticer\n",
    "        critic_loss, critic_loss_grad = jit_critic_loss_g_value(critic_params, batch)\n",
    "        \n",
    "        # Update params\n",
    "        critic_updates, critic_opt_state = jit_critic_tx_update(critic_loss_grad, critic_opt_state)\n",
    "        critic_params = jit_apply_update(critic_params, critic_updates)\n",
    "    \n",
    "    print(\"criticer loss:\",critic_loss)\n",
    "    # controller\n",
    "    \n",
    "    # for j in range(3):\n",
    "    keys = jax.random.split(key,controller_batch_size)\n",
    "    controller_batch = jit_sample(exp_pool, controller_batch_size, key)\n",
    "    key = jax.random.split(key, 1)[0]\n",
    "    controller_loss_exps, controller_loss_grad = jit_g_loss_experience(\n",
    "        controller_params, critic_params, controller_batch, mjx_model, init_data_batch, keys)\n",
    "    controller_loss = controller_loss_exps[0]\n",
    "    exps = controller_loss_exps[1]\n",
    "        \n",
    "    # Update params\n",
    "    controller_updates, controller_opt_state = jit_controller_tx_update(controller_loss_grad, controller_opt_state)\n",
    "    controller_params = jit_apply_update(controller_params, controller_updates)\n",
    "    \n",
    "    exp_pool = jit_add_exp(memory_settings, exp_pool, exps)\n",
    "    \n",
    "    # Count Dones\n",
    "    death_rate_buf.insert(0, jp.count_nonzero( exps.dones)/(exps.dones.shape[1]*controller_batch_size))\n",
    "    death_rate_buf = death_rate_buf[:50]\n",
    "    death_rate = np.mean(death_rate_buf)\n",
    "    \n",
    "    print(\"Controller Loss:\", controller_loss)\n",
    "    mean_reward = jp.mean(exps.rewards)\n",
    "    print(\"mean rewards:\", mean_reward)\n",
    "    mean_score = jp.mean(jit_v_criticer(critic_params, exps.states))\n",
    "    print(\"mean score:\", mean_score)\n",
    "    print(\"scorc/reward:\", mean_score/mean_reward)\n",
    "    print(\"death rate:\", death_rate)\n",
    "    \n",
    "    if(best_death_rate > death_rate): best_death_rate = death_rate\n",
    "    print(\"best_death_rate:\", best_death_rate)\n",
    "    # add exps\n",
    "    \n",
    "    if(i%20 == 0):\n",
    "        plt.figure()\n",
    "        plt.plot(exp_pool.rewards)\n",
    "        plt.plot()\n",
    "        # plt.plot(exp_pool.rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the model and controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mujoco.viewer\n",
    "import time\n",
    "\n",
    "\n",
    "# Disable tendon\n",
    "opt = mjx_model.opt.replace(disableflags = mjx_model.opt.disableflags |mujoco.mjtDisableBit.mjDSBL_PASSIVE)\n",
    "mjx_model = mjx_model.replace(opt=opt)\n",
    "\n",
    "mjx_data = mjx.make_data(mjx_model)\n",
    "mj_data = mujoco.MjData(mj_model)\n",
    "\n",
    "# Load the Keyframe\n",
    "mjx_data = mjx_data.replace(qpos = mj_model.key_qpos[0])\n",
    "mj_data.qpos = mj_model.key_qpos[0]\n",
    "\n",
    "# Calculate equilibrum\n",
    "mjx_data = acceleration_mtu.calc_equilibrium(mjx_model, mjx_data)\n",
    "\n",
    "previous_frame_time = time.time()\n",
    "i = 0\n",
    "key = jax.random.key(334)\n",
    "with mujoco.viewer.launch_passive(mj_model, mj_data) as viewer:\n",
    "    while viewer.is_running():\n",
    "        # Update mjx_data from mj_data. The mj_data was modified by the viewer\n",
    "        # mjx_data = mjx_data.replace(ctrl=mj_data.ctrl, xfrc_applied=mj_data.xfrc_applied)\n",
    "        # Use the nerual network to generate ctrl signal\n",
    "        \n",
    "        mjx_data = mjx_data.replace(xfrc_applied=jp.array(mj_data.xfrc_applied, dtype=jp.float32))\n",
    "        \n",
    "        # Generate key\n",
    "        key = jax.random.split(key,1)[0]\n",
    "        # xfrc = jax.random.uniform(key,(mjx_model.nbody, 6), minval=-10, maxval=10)\n",
    "        # mjx_data = mjx_data.replace(xfrc_applied=xfrc)\n",
    "        mjx_data = mjx_data.replace(\n",
    "            qpos= jp.array(mj_data.qpos, dtype=jp.float32),\n",
    "            qvel= jp.array(mj_data.qvel, dtype=jp.float32),\n",
    "            time = jp.array(mj_data.time, dtype=jp.float32))\n",
    "        \n",
    "        # Update mjx_model from mj_model\n",
    "        mjx_model = mjx_model.tree_replace({\n",
    "            'opt.gravity': jp.array(mj_model.opt.gravity, dtype=jp.float32),\n",
    "            'opt.tolerance': jp.array(mj_model.opt.tolerance, dtype=jp.float32),\n",
    "            'opt.ls_tolerance': jp.array(mj_model.opt.ls_tolerance, dtype=jp.float32),\n",
    "            'opt.timestep': jp.array(mj_model.opt.timestep, dtype=jp.float32),\n",
    "        })\n",
    "        \n",
    "        # mjx_data = mjx_step(mjx_model, mjx_data)\n",
    "        # mjx_data, loss, exps = jit_nn_multi_steps(controller_params, mjx_model, mjx_data, key)\n",
    "        mjx_data, key, act = jit_nn_mjx_one_step_no_random(controller_params, mjx_model, mjx_data, key)\n",
    "        mjx.get_data_into(mj_data, mj_model, mjx_data)\n",
    "        \n",
    "        # Record the current time at the start of this frame\n",
    "        current_frame_time = time.time()\n",
    "    \n",
    "        # Calculate the difference in time from the last frame\n",
    "        time_between_frames = current_frame_time - previous_frame_time\n",
    "    \n",
    "        # Print the time between frames\n",
    "        print(f\"Time between frames: {time_between_frames} seconds\")\n",
    "        previous_frame_time = current_frame_time\n",
    "        \n",
    "        # print(\"ACT:\", mjx_data.biomtu.act)\n",
    "        # print(mjx_data.qpos)\n",
    "        # print(mj_data.sen)  \n",
    "        print(mjx_data.sensordata[2])\n",
    "        print(mjx_data.biomtu.act)\n",
    "        # print(len(mjx_data.qvel))\n",
    "        viewer.sync()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biomujoco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
