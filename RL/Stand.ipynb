{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RL code to teach the model to stand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup jax enviroment and Load Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mediapy as media\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../Biodiffrl\")\n",
    "\n",
    "import os\n",
    "# os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \".60\"\n",
    "\n",
    "# Optionally, force JAX to preallocate memory.\n",
    "# os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"true\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "\n",
    "# Setup environment variable for Nvidia GPU acceleration\n",
    "os.environ['XLA_FLAGS'] = (\n",
    "    # '--xla_gpu_enable_triton_softmax_fusion=true '\n",
    "    '--xla_gpu_triton_gemm_any=True '\n",
    "    # '--xla_gpu_enable_async_collectives=true '\n",
    "    # '--xla_gpu_enable_latency_hiding_scheduler=true '\n",
    "    '--xla_gpu_enable_highest_priority_async_stream=true '\n",
    "    # '--xla_cpu_multi_thread_eigen=true intra_op_parallelism_threads=32'\n",
    ")\n",
    "\n",
    "backend = 'gpu'\n",
    "# backend = 'METAL'\n",
    "# backend = 'cpu'\n",
    "\n",
    "import jax\n",
    "jax.config.update('jax_platform_name', 'gpu')\n",
    "os.environ[\"TF_XLA_FLAGS\"] = \"--tf_xla_enable_lazy_compilation=false\"\n",
    "# Enable compliation catch\n",
    "os.environ[\"JAX_COMPILATION_CACHE_DIR\"] = \"./jax_cache\"\n",
    "jax.config.update(\"jax_compilation_cache_dir\", \"./jax_cache\")\n",
    "jax.config.update(\"jax_persistent_cache_min_entry_size_bytes\", 0)\n",
    "jax.config.update(\"jax_persistent_cache_min_compile_time_secs\", 2)\n",
    "# jax.config.update(\"jax_explain_cache_misses\", True)\n",
    "\n",
    "from jax.experimental.compilation_cache import compilation_cache as cc\n",
    "cc.set_cache_dir(\"./jax_cache\")\n",
    "# Debug Nan\n",
    "# jax.config.update(\"jax_debug_nans\", True)\n",
    "\n",
    "from jax import numpy as jp\n",
    "# More legible printing from numpy.\n",
    "jp.set_printoptions(precision=4, suppress=True, linewidth=100)\n",
    "\n",
    "import mujoco\n",
    "import mujoco.mjx as mjx\n",
    "from mujoco.mjx._src import scan\n",
    "from mujoco.mjx._src import types\n",
    "\n",
    "# More legible printing from numpy.\n",
    "np.set_printoptions(precision=4, suppress=True, linewidth=100)\n",
    "\n",
    "from IPython.display import clear_output\n",
    "clear_output()\n",
    "\n",
    "device = jax.devices(backend=backend)[0]\n",
    "\n",
    "model_path = '/home/bugman/Currentwork/biomujoco_converter/converted/mjc/Gait2354/gait2354_cvt1.xml'\n",
    "\n",
    "# Single step\n",
    "mjx_step = jax.jit(mjx.step, backend=backend)\n",
    "\n",
    "\n",
    "\n",
    "# mjx_multiple_steps = jax.jit(multiple_steps, backend=backend, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "27\n",
      "[ 0.      0.9501  0.      0.0006  0.     -0.     -0.0013 -0.     -0.0009 -0.0037 -0.3957  0.0023\n",
      " -0.0199 -0.0032  0.0228 -0.0013 -0.     -0.0009 -0.0037 -0.3957  0.0023 -0.0199 -0.0032  0.0228\n",
      " -0.0007 -0.      0.    ]\n",
      "[ 0.0149  0.0271  0.      0.3064  0.     -0.     -0.6693 -0.0194 -0.4365 -0.0074  0.0056  1.1327\n",
      " -9.9627 -1.625  11.377  -0.6693 -0.0194 -0.4365 -0.0074  0.0056  1.1327 -9.9628 -1.625  11.377\n",
      " -0.3256 -0.      0.    ]\n"
     ]
    }
   ],
   "source": [
    "from mujoco.mjx._src.biomtu import acceleration_mtu\n",
    "\n",
    "mj_model = mujoco.MjModel.from_xml_path(model_path)\n",
    "mjx_model = mjx.put_model(mj_model,device=device)\n",
    "\n",
    "# Disable tendon\n",
    "opt = mjx_model.opt.replace(disableflags = mjx_model.opt.disableflags |mujoco.mjtDisableBit.mjDSBL_PASSIVE)\n",
    "mjx_model = mjx_model.replace(opt=opt)\n",
    "\n",
    "mjx_data = mjx.make_data(mjx_model)\n",
    "mj_data = mujoco.MjData(mj_model)\n",
    "\n",
    "# Load the Keyframe\n",
    "mjx_data = mjx_data.replace(qpos = mj_model.key_qpos[0])\n",
    "mj_data.qpos = mj_model.key_qpos[0]\n",
    "\n",
    "# Calculate equilibrum\n",
    "mjx_data = acceleration_mtu.calc_equilibrium(mjx_model, mjx_data)\n",
    "mjx_data = jax.jit(mjx_step)(mjx_model, mjx_data)\n",
    "\n",
    "init_mjx_data = mjx_data\n",
    "\n",
    "def print_all():\n",
    "    print(mjx_model.biomtu_adr)\n",
    "    print(mjx_model.mtu_wrap_objid)\n",
    "    print(mjx_model.mtu_wrap_type)\n",
    "    print(mjx_model.biomtu_fiso)\n",
    "    print(mjx_model.biomtu_vmax)\n",
    "    print(mjx_model.biomtu_ofl)\n",
    "    print(mjx_model.biomtu_opa)\n",
    "    print(mjx_model.biomtu_mass)\n",
    "    print(\"-------Data--------\")\n",
    "    print(\"qpos:\", mjx_data.qpos)\n",
    "    print(\"mtu l:\", mjx_data.biomtu.l)\n",
    "    print(\"tendon l:\", mjx_data.biomtu.tendon_l)\n",
    "    print(\"fiber l :\", mjx_data.biomtu.fiber_l)\n",
    "    print(\"Muscle Bce:\", mjx_data.biomtu.B_ce)\n",
    "    print(\"Muscle vm:\", mjx_data.biomtu.m)\n",
    "    print(\"Fiber acc:\", mjx_data.biomtu.fiber_acc)\n",
    "    print(\"Fiber v:\", mjx_data.biomtu.fiber_v)\n",
    "    print(\"Biomtu h:\", mjx_data.biomtu.h)\n",
    "    print(mjx_data.biomtu.v)\n",
    "    print(mjx_data.biomtu.h)  # The constant high of the muscle.\n",
    "    print(mjx_data.biomtu.pennation_angle)\n",
    "    print(mjx_data.biomtu.origin_body_id)\n",
    "    print(mjx_data.biomtu.insertion_body_id)\n",
    "    print(\"mtu act:\", mjx_data.biomtu.act)\n",
    "    # print(mjx_data.biomtu.j)\n",
    "    print(mjx_data.qfrc_biomtu)\n",
    "    print(mj_model.key_time)\n",
    "    print(mj_model.key_qpos)\n",
    "    print(mj_model.key_qvel)\n",
    "\n",
    "# print_all()\n",
    "\n",
    "print(mjx_model.nbiomtu)\n",
    "print(mjx_model.nq)\n",
    "print(mjx_data.qpos)\n",
    "print(mjx_data.qvel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54,)\n",
      "(Array([0.1488, 0.    , 0.0987, 0.2666, 0.    , 0.2967, 0.    , 0.    , 0.    , 0.    , 0.    ,\n",
      "       0.    , 0.    , 0.1996, 0.2439, 0.    , 0.    , 0.    , 0.215 , 0.3028, 0.    , 0.    ,\n",
      "       0.2961, 0.    , 0.4897, 0.598 , 0.    , 0.    , 0.1105, 0.    , 0.3579, 0.3427, 0.    ,\n",
      "       0.    , 0.1568, 0.355 , 0.194 , 0.    , 0.    , 0.1536, 0.    , 0.    , 0.1321, 0.6448,\n",
      "       0.    , 0.2723, 0.    , 0.    , 0.    , 0.0218, 0.    , 0.2099, 0.    , 0.    ],      dtype=float32), Array([0.2006, 0.0239, 0.1653, 0.3102, 0.    , 0.3476, 0.    , 0.    , 0.0396, 0.    , 0.    ,\n",
      "       0.    , 0.    , 0.2458, 0.2882, 0.    , 0.    , 0.    , 0.2859, 0.346 , 0.    , 0.    ,\n",
      "       0.3306, 0.    , 0.5448, 0.6572, 0.    , 0.0215, 0.1492, 0.    , 0.4006, 0.3831, 0.    ,\n",
      "       0.    , 0.2316, 0.3897, 0.2437, 0.    , 0.    , 0.2122, 0.    , 0.    , 0.1918, 0.6812,\n",
      "       0.    , 0.2966, 0.    , 0.    , 0.    , 0.0958, 0.    , 0.284 , 0.    , 0.    ],      dtype=float32), Array([ 0.0455,  0.625 ,  0.2978, -0.1272, -0.6332,  0.0294,  0.7894, -0.2805,  0.0391, -0.6006,\n",
      "       -0.9464, -0.3872,  0.6687, -0.0669, -0.11  , -0.1769,  0.1054,  0.0858,  0.3607, -0.1353,\n",
      "       -0.1823, -0.4416, -0.3589, -0.6479,  0.1091,  0.1793, -0.1549, -0.5436, -0.2442, -0.1488,\n",
      "       -0.1445, -0.2008,  0.483 , -0.4869,  0.4144, -0.3555,  0.0066, -0.5483,  0.3142,  0.1712,\n",
      "       -0.256 , -0.7262,  0.1894, -0.3055,  0.0192, -0.7103,  0.6754, -0.0019,  0.0216,  0.4036,\n",
      "       -0.1126,  0.4048, -0.2863, -0.0865], dtype=float32))\n",
      "[-0.]\n"
     ]
    }
   ],
   "source": [
    "import nn\n",
    "\n",
    "key = jax.random.key(2024)\n",
    "# Controller NN\n",
    "controller_nn = nn.Controller_NN(mjx_model.nq*2+mjx_model.nbiomtu*2, mjx_model.nbiomtu)\n",
    "controller_params, key = controller_nn.init_parameters(key)\n",
    "controller = controller_nn.get_fn()\n",
    "\n",
    "# Critic NN\n",
    "critic_nn = nn.Critic_NN(mjx_model.nq*2 + mjx_model.nbiomtu*2,1)\n",
    "critic_params, key = critic_nn.init_parameters(key)\n",
    "criticer = critic_nn.get_fn()\n",
    "\n",
    "# Test the two neural networks\n",
    "controller_output = controller(controller_params, jp.ones(mjx_model.nq*2+mjx_model.nbiomtu*2), key)\n",
    "print(controller_output[0].shape)\n",
    "print(controller_output)\n",
    "print(criticer(critic_params, jp.ones(mjx_model.nq*2+mjx_model.nbiomtu*2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "# Since the environment resets with init_mjx_data, the muscles are already in the equilibrum condition.\n",
    "def reset(init_mjx_data, batch_size):\n",
    "    new_data = jax.tree.map(\n",
    "        partial(jp.repeat, repeats=batch_size, axis=0),\n",
    "        jax.tree.map(partial(jp.expand_dims, axis=0),init_mjx_data))\n",
    "    return new_data\n",
    "\n",
    "def random_init(data, model, rng: jax.Array):\n",
    "    nbiomtu = model.nq\n",
    "    init_qpos = data.qpos\n",
    "    init_qvel = data.qvel\n",
    "    new_rng, rng1, rng2 = jax.random.split(rng, 3)\n",
    "    # Qpos_1 is the vertical position\n",
    "    random_qpos = init_qpos + jax.random.uniform(rng1, [nbiomtu], minval=jp.array(-1.0, dtype=jp.float32), maxval=jp.array(1.0, dtype=jp.float32))*0.01\n",
    "    random_qvel = init_qvel + jax.random.uniform(rng2, [nbiomtu], minval=jp.array(-1.0, dtype=jp.float32), maxval=jp.array(1.0, dtype=jp.float32))*0.01\n",
    "    newdata = data.replace(qpos=random_qpos)\n",
    "    newdata = newdata.replace(qvel=random_qvel)\n",
    "    newdata = mjx.forward(mjx_model, newdata)\n",
    "    # print('data:',data.qpos, data.qvel)\n",
    "    # Calculate equilibrum\n",
    "    # newdata = acceleration_mtu.calc_equilibrium(mjx_model, newdata)\n",
    "    # newdata = mjx_step(mjx_model, newdata)\n",
    "    return newdata, new_rng\n",
    "\n",
    "vrandom_init = jax.jit(jax.vmap(random_init, in_axes=(None, None, 0), out_axes=0))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-steps forward simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import exp\n",
    "\n",
    "# Multiple steps\n",
    "def step_fn(carry, _):\n",
    "    model, data= carry\n",
    "    new_data = mjx.step(model, data)\n",
    "    new_carry = (model, new_data)\n",
    "    return new_carry, _\n",
    "\n",
    "def multiple_steps(model, data):\n",
    "    init_carry = (model, data)\n",
    "    y, _ = jax.lax.scan(step_fn, init_carry, None, length=10)\n",
    "    new_data = y[0]\n",
    "    return new_data\n",
    "\n",
    "# For one step\n",
    "def nn_mjx_one_step(nn_params, model, data, key):\n",
    "    states = jp.concatenate([data.qpos, data.qvel, data.biomtu.fiber_l, data.biomtu.fiber_v])\n",
    "    act, mean, std = controller(nn_params, states, key)\n",
    "    # Generate the next key\n",
    "    new_key = jax.random.split(key,1)[0]\n",
    "    data = data.replace(biomtu = data.biomtu.replace(act = act))\n",
    "    new_data = mjx.step(model, data)\n",
    "    return new_data, new_key, act\n",
    "\n",
    "def nn_mjx_perturbe_one_step(nn_params, model, data, key):\n",
    "    states = jp.concatenate([data.qpos, data.qvel, data.biomtu.fiber_l, data.biomtu.fiber_v])\n",
    "    act, mean, std = controller(nn_params, states, key)\n",
    "    # Generate the next key\n",
    "    new_key = jax.random.split(key,1)[0]\n",
    "    data = data.replace(biomtu = data.biomtu.replace(act = act))\n",
    "    xfrc = jax.random.normal(key,(mjx_model.nbody, 6))*1.0\n",
    "    data = data.replace(xfrc_applied=xfrc)\n",
    "    new_data = mjx.step(model, data)\n",
    "    return new_data, new_key, act\n",
    "\n",
    "@jax.jit\n",
    "def jit_nn_mjx_one_step_no_random(nn_params, model, data, key):\n",
    "    states = jp.concatenate([data.qpos, data.qvel, data.biomtu.fiber_l, data.biomtu.fiber_v])\n",
    "    act, mean, std = controller(nn_params, states, key)\n",
    "    # Generate the next key\n",
    "    new_key = jax.random.split(key,1)[0]\n",
    "    data = data.replace(biomtu = data.biomtu.replace(act = act))\n",
    "    new_data = mjx.step(model, data)\n",
    "    return new_data, new_key, mean\n",
    "\n",
    "def nn_step_fn(carry, _):\n",
    "    nn_params, model, data, key = carry\n",
    "    new_data, new_key, act = nn_mjx_one_step(nn_params, model, data, key)\n",
    "    # new_data, new_key, act = nn_mjx_perturbe_one_step(nn_params, model, data, key)\n",
    "    new_carry = (nn_params, model, new_data, new_key)\n",
    "    # Calculate reward\n",
    "    head_height = new_data.sensordata[2]\n",
    "    state = jp.concat([data.qpos, data.qvel, data.biomtu.fiber_l, data.biomtu.fiber_v])\n",
    "    next_state = jp.concat([new_data.qpos, new_data.qvel, new_data.biomtu.fiber_l, new_data.biomtu.fiber_v])\n",
    "    action = act\n",
    "    # done = head_hight < 1.2\n",
    "    done = jp.where(head_height <= 1, jp.float32(1), jp.float32(0))\n",
    "    reward = -(head_height-1.63)**2 - done*0.5\n",
    "    experience = exp.experience(state, next_state, action, reward, done)\n",
    "    \n",
    "    return new_carry, experience\n",
    "\n",
    "@jax.jit\n",
    "def nn_multi_steps(nn_params, model, data, key):\n",
    "    # Also deal with the done in the experience pool\n",
    "    \n",
    "    repeat_length = 50  # Simulate for 0.1s\n",
    "    init_carry = (nn_params, model, data, key)\n",
    "    y, experience = jax.lax.scan(nn_step_fn, init_carry, None, length=repeat_length)\n",
    "    new_data = y[2]\n",
    "    new_key = y[3]\n",
    "    return new_data, new_key, experience\n",
    "\n",
    "jit_nn_multi_steps = jax.jit(nn_multi_steps)\n",
    "\n",
    "# @jax.jit\n",
    "def v_nn_multi_steps(nn_params, model, data, keys):\n",
    "    return jax.vmap(nn_multi_steps, in_axes=(None, None, 0, 0))(nn_params, model, data, keys)\n",
    "\n",
    "jit_v_nn_multi_steps = jax.jit(v_nn_multi_steps)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "import exp\n",
    "\n",
    "critic_batch_size = 64*10\n",
    "controller_batch_size = 64\n",
    "key = jax.random.key(2024)\n",
    "keys = jax.random.split(key, controller_batch_size)\n",
    "\n",
    "memory_settings = exp.memory_settings(critic_batch_size*126, mjx_model.nq*2+mjx_model.nbiomtu*2, mjx_model.nbiomtu, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate initial experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 162)\n"
     ]
    }
   ],
   "source": [
    "exp_pool = None\n",
    "datas = jax.jit(reset,static_argnames=\"batch_size\")(init_mjx_data, controller_batch_size)\n",
    "init_data_batch = datas\n",
    "for i in range(5):\n",
    "    datas, keys, exps = jit_v_nn_multi_steps(controller_params, mjx_model, datas, keys)\n",
    "    # print(datas.qvel.shape, datas.ten_J.shape)\n",
    "    exp_pool = exp.memory.add_exp(memory_settings, exp_pool, exps)\n",
    "    \n",
    "print(exp_pool.states.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Critic gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19671028.0\n"
     ]
    }
   ],
   "source": [
    "import optax\n",
    "\n",
    "v_criticer = jax.vmap(criticer,in_axes=(None, 0))\n",
    "jit_v_criticer = jax.jit(v_criticer)\n",
    "\n",
    "def critic_loss(params, batch):\n",
    "    discount = 0.95\n",
    "    states = batch.states\n",
    "    next_states = batch.next_states\n",
    "    actions = batch.actions\n",
    "    rewards = batch.rewards\n",
    "    \n",
    "    critic_score = v_criticer(params, states)\n",
    "    # target = rewards + discount* jax.lax.stop_gradient(v_criticer(params, next_states))\n",
    "    target = rewards + discount* (v_criticer(params, next_states))\n",
    "    \n",
    "    loss = optax.l2_loss(critic_score, target)\n",
    "    loss = jp.mean(loss)\n",
    "    return loss\n",
    "\n",
    "sample_batch = exp.memory.sample(exp_pool, critic_batch_size, key)\n",
    "critic_loss_g_value_lower= jax.jit(jax.value_and_grad(critic_loss)).lower(critic_params, sample_batch)\n",
    "\n",
    "jit_critic_loss_g_value = critic_loss_g_value_lower.compile()\n",
    "a=jit_critic_loss_g_value.cost_analysis()[0]['flops']\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Actor gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lowering\n",
      "compiling\n",
      "290555872.0\n"
     ]
    }
   ],
   "source": [
    "def controller_loss_and_experience(controller_params, critic_params, batch, batch_size, mjx_model, init_data_batch, keys):\n",
    "    # Generate data for simulation\n",
    "    nq = mjx_model.nq\n",
    "    nmtu = mjx_model.nbiomtu\n",
    "    \n",
    "    # Deal with the done state, reset the done state with init state\n",
    "    # exp_data_batch = init_data_batch.replace(\n",
    "    #     qpos = batch.states[:,0:nq], \n",
    "    #     qvel = batch.states[:,nq:nq*2],\n",
    "    #     biomtu = init_data_batch.biomtu.replace(\n",
    "    #         fiber_l = batch.states[nq*2, nq*2+nmtu],\n",
    "    #         fiber_v = batch.states[nq*2+nmtu, nq*2+nmtu*2]\n",
    "    #     ))\n",
    "    \n",
    "    qpos = jp.where(batch.dones, init_data_batch.qpos, batch.states[:,0:nq])\n",
    "    qvel = jp.where(batch.dones, init_data_batch.qvel, batch.states[:,nq:nq*2])\n",
    "    fiber_l = jp.where(batch.dones, init_data_batch.biomtu.fiber_l, batch.states[:,nq*2 : nq*2+nmtu])\n",
    "    fiber_v = jp.where(batch.dones, init_data_batch.biomtu.fiber_v, batch.states[:,nq*2+nmtu : nq*2+nmtu*2])\n",
    "    \n",
    "    # in_data = batch.dones, init_data_batch, exp_data_batch)\n",
    "    \n",
    "    in_data = jax.lax.stop_gradient(init_data_batch.replace(\n",
    "        qpos = qpos,\n",
    "        qvel = qvel,\n",
    "        biomtu = init_data_batch.biomtu.replace(\n",
    "            fiber_l = fiber_l,\n",
    "            fiber_v = fiber_v)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    out_data, keys, new_exps = v_nn_multi_steps(controller_params, mjx_model, in_data, keys)\n",
    "    # out_states = jp.concat([out_data.qpos, out_data.qvel],axis=1).reshape(batch_size,4)\n",
    "    out_states = new_exps.next_states\n",
    "    # jax.debug.print(\"out_states shape{0}\", out_states.shape)\n",
    "    # out_states = jp.concat([out_data.qpos, out_data.qvel, out_data.biomtu.fiber_l, out_data.biomtu.fiber_v],axis=1)\n",
    "    critic_score = v_criticer(critic_params, out_states)\n",
    "    \n",
    "    loss = -jp.mean(critic_score)\n",
    "    return loss, new_exps\n",
    "\n",
    "# The function calculating the loss of the controller and also generate experiences\n",
    "g_loss_experience = jax.value_and_grad(controller_loss_and_experience, has_aux=True)\n",
    "\n",
    "controller_keys = jax.random.split(key, controller_batch_size)\n",
    "sample_batch = exp.memory.sample(exp_pool, controller_batch_size, key)\n",
    "\n",
    "print(\"lowering\")\n",
    "g_loss_experience_lower = jax.jit(g_loss_experience, static_argnames=[\"batch_size\"]).lower(\n",
    "    controller_params, \n",
    "    critic_params, \n",
    "    sample_batch, \n",
    "    controller_batch_size, \n",
    "    mjx_model, \n",
    "    init_data_batch, \n",
    "    controller_keys)\n",
    "\n",
    "print(\"compiling\")\n",
    "jit_g_loss_experience = g_loss_experience_lower.compile()\n",
    "\n",
    "b = jit_g_loss_experience.cost_analysis()[0]['flops']\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 162)\n",
      "14.770751787857757\n"
     ]
    }
   ],
   "source": [
    "print(sample_batch.states.shape)\n",
    "print(b/a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the two neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7319f7851090>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "key = jax.random.key(9346)\n",
    "keys = jax.random.split(key, controller_batch_size)\n",
    "\n",
    "critic_params, key = critic_nn.init_parameters(key)\n",
    "critic_tx = optax.apply_if_finite(optax.adam(learning_rate=1e-5), max_consecutive_errors=50)\n",
    "# critic_tx = optax.apply_if_finite(optax.sgd(learning_rate=1e-4), max_consecutive_errors=50)\n",
    "critic_opt_state = critic_tx.init(critic_params)\n",
    "jit_critic_tx_update = jax.jit(critic_tx.update)\n",
    "\n",
    "\n",
    "controller_params, key = controller_nn.init_parameters(key)\n",
    "controller_tx = optax.apply_if_finite(optax.adam(learning_rate=1e-5), max_consecutive_errors=50)\n",
    "# controller_tx = optax.apply_if_finite(optax.sgd(learning_rate=1e-4), max_consecutive_errors=50)\n",
    "controller_opt_state = controller_tx.init(controller_params)\n",
    "jit_controller_tx_update = jax.jit(controller_tx.update)\n",
    "\n",
    "jit_apply_update = jax.jit(optax.apply_updates)\n",
    "\n",
    "\n",
    "jit_sample = jax.jit(exp.memory.sample, static_argnames=\"batch_size\")\n",
    "jit_add_exp = jax.jit(exp.memory.add_exp, static_argnames=\"settings\")\n",
    "\n",
    "# Init exp_pool\n",
    "exp_pool = None\n",
    "datas = reset(init_mjx_data,controller_batch_size)\n",
    "for i in range(6):\n",
    "    datas, keys, exps = jit_v_nn_multi_steps(controller_params, mjx_model, datas, keys)\n",
    "    # print(datas.qvel.shape, datas.ten_J.shape)\n",
    "    if(i>2):\n",
    "        exp_pool = exp.memory.add_exp(memory_settings, exp_pool, exps)\n",
    "\n",
    "#plot exp_pool\n",
    "# plt.plot(exp_pool.states.T[1])\n",
    "plt.plot(exp_pool.rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- 0 ----------\n",
      "criticer loss: 2.16725\n",
      "Controller Loss: 0.050518468\n",
      "mean rewards: -0.99777967\n",
      "mean score: -0.05018127\n",
      "scorc/reward: 0.050292935\n",
      "death rate: 0.161875\n",
      "best_death_rate: 0.161875\n",
      "---------- 1 ----------\n",
      "criticer loss: 2.4740562\n",
      "Controller Loss: 0.21703205\n",
      "mean rewards: -0.96816415\n",
      "mean score: -0.21670498\n",
      "scorc/reward: 0.22383082\n",
      "death rate: 0.15984374\n",
      "best_death_rate: 0.15984374\n",
      "---------- 2 ----------\n",
      "criticer loss: 2.3020933\n",
      "Controller Loss: 0.5106904\n",
      "mean rewards: -1.1903692\n",
      "mean score: -0.50908947\n",
      "scorc/reward: 0.42767358\n",
      "death rate: 0.1728125\n",
      "best_death_rate: 0.15984374\n",
      "---------- 3 ----------\n",
      "criticer loss: 2.417718\n",
      "Controller Loss: 0.77685964\n",
      "mean rewards: -1.0418668\n",
      "mean score: -0.7782591\n",
      "scorc/reward: 0.74698526\n",
      "death rate: 0.17289062\n",
      "best_death_rate: 0.15984374\n",
      "---------- 4 ----------\n",
      "criticer loss: 1.9673861\n",
      "Controller Loss: 1.0447818\n",
      "mean rewards: -0.7217024\n",
      "mean score: -1.0436459\n",
      "scorc/reward: 1.446089\n",
      "death rate: 0.16131249\n",
      "best_death_rate: 0.15984374\n",
      "---------- 5 ----------\n",
      "criticer loss: 2.1246727\n",
      "Controller Loss: 1.4466292\n",
      "mean rewards: -0.7011618\n",
      "mean score: -1.4439962\n",
      "scorc/reward: 2.0594337\n",
      "death rate: 0.15255208\n",
      "best_death_rate: 0.15255208\n",
      "---------- 6 ----------\n",
      "criticer loss: 2.4933984\n",
      "Controller Loss: 1.5172195\n",
      "mean rewards: -0.5882989\n",
      "mean score: -1.5195228\n",
      "scorc/reward: 2.5829093\n",
      "death rate: 0.14388393\n",
      "best_death_rate: 0.14388393\n",
      "---------- 7 ----------\n",
      "criticer loss: 2.3837647\n",
      "Controller Loss: 2.0481038\n",
      "mean rewards: -0.9753648\n",
      "mean score: -2.044493\n",
      "scorc/reward: 2.0961316\n",
      "death rate: 0.1459375\n",
      "best_death_rate: 0.14388393\n",
      "---------- 8 ----------\n",
      "criticer loss: 1.8152943\n",
      "Controller Loss: 2.1934927\n",
      "mean rewards: -0.87496513\n",
      "mean score: -2.1930861\n",
      "scorc/reward: 2.506484\n",
      "death rate: 0.14565971\n",
      "best_death_rate: 0.14388393\n",
      "---------- 9 ----------\n",
      "criticer loss: 1.6355692\n",
      "Controller Loss: 2.4312418\n",
      "mean rewards: -0.6420766\n",
      "mean score: -2.4315941\n",
      "scorc/reward: 3.787078\n",
      "death rate: 0.14128125\n",
      "best_death_rate: 0.14128125\n",
      "---------- 10 ----------\n",
      "criticer loss: 2.024635\n",
      "Controller Loss: 2.9840033\n",
      "mean rewards: -1.0444859\n",
      "mean score: -2.9878752\n",
      "scorc/reward: 2.8606179\n",
      "death rate: 0.14428976\n",
      "best_death_rate: 0.14128125\n",
      "---------- 11 ----------\n",
      "criticer loss: 2.1392581\n",
      "Controller Loss: 3.6306446\n",
      "mean rewards: -0.920952\n",
      "mean score: -3.6292987\n",
      "scorc/reward: 3.940812\n",
      "death rate: 0.1446875\n",
      "best_death_rate: 0.14128125\n",
      "---------- 12 ----------\n",
      "criticer loss: 2.0873086\n",
      "Controller Loss: 3.8663619\n",
      "mean rewards: -1.0280615\n",
      "mean score: -3.8735094\n",
      "scorc/reward: 3.7677796\n",
      "death rate: 0.14673077\n",
      "best_death_rate: 0.14128125\n",
      "---------- 13 ----------\n",
      "criticer loss: 1.7980425\n",
      "Controller Loss: 4.3968797\n",
      "mean rewards: -0.9174794\n",
      "mean score: -4.400474\n",
      "scorc/reward: 4.796265\n",
      "death rate: 0.14691964\n",
      "best_death_rate: 0.14128125\n",
      "---------- 14 ----------\n",
      "criticer loss: 2.0287209\n",
      "Controller Loss: 4.247769\n",
      "mean rewards: -0.9263469\n",
      "mean score: -4.254018\n",
      "scorc/reward: 4.592252\n",
      "death rate: 0.14745833\n",
      "best_death_rate: 0.14128125\n",
      "---------- 15 ----------\n",
      "criticer loss: 1.5632073\n",
      "Controller Loss: 5.103128\n",
      "mean rewards: -0.88503706\n",
      "mean score: -5.1074944\n",
      "scorc/reward: 5.7709384\n",
      "death rate: 0.14730468\n",
      "best_death_rate: 0.14128125\n",
      "---------- 16 ----------\n",
      "criticer loss: 1.9586247\n",
      "Controller Loss: 5.5114026\n",
      "mean rewards: -0.8013911\n",
      "mean score: -5.5176396\n",
      "scorc/reward: 6.885077\n",
      "death rate: 0.14630516\n",
      "best_death_rate: 0.14128125\n",
      "---------- 17 ----------\n",
      "criticer loss: 1.725804\n",
      "Controller Loss: 6.3000727\n",
      "mean rewards: -0.96559936\n",
      "mean score: -6.3064427\n",
      "scorc/reward: 6.531117\n",
      "death rate: 0.14696181\n",
      "best_death_rate: 0.14128125\n",
      "---------- 18 ----------\n",
      "criticer loss: 1.6404679\n",
      "Controller Loss: 5.936384\n",
      "mean rewards: -0.6781529\n",
      "mean score: -5.951951\n",
      "scorc/reward: 8.77671\n",
      "death rate: 0.14500001\n",
      "best_death_rate: 0.14128125\n",
      "---------- 19 ----------\n",
      "criticer loss: 1.6588068\n",
      "Controller Loss: 6.7261972\n",
      "mean rewards: -0.94178617\n",
      "mean score: -6.7456017\n",
      "scorc/reward: 7.162562\n",
      "death rate: 0.14560938\n",
      "best_death_rate: 0.14128125\n",
      "---------- 20 ----------\n",
      "criticer loss: 1.5628988\n",
      "Controller Loss: 7.189912\n",
      "mean rewards: -0.7996348\n",
      "mean score: -7.1955566\n",
      "scorc/reward: 8.998553\n",
      "death rate: 0.14483632\n",
      "best_death_rate: 0.14128125\n",
      "---------- 21 ----------\n",
      "criticer loss: 1.4640692\n",
      "Controller Loss: 6.8980827\n",
      "mean rewards: -0.89746535\n",
      "mean score: -6.948214\n",
      "scorc/reward: 7.742041\n",
      "death rate: 0.14509945\n",
      "best_death_rate: 0.14128125\n",
      "---------- 22 ----------\n",
      "criticer loss: 1.7933449\n",
      "Controller Loss: 8.137965\n",
      "mean rewards: -1.1654282\n",
      "mean score: -8.190493\n",
      "scorc/reward: 7.027883\n",
      "death rate: 0.14747284\n",
      "best_death_rate: 0.14128125\n",
      "---------- 23 ----------\n",
      "criticer loss: 1.538118\n",
      "Controller Loss: 9.825995\n",
      "mean rewards: -0.9833288\n",
      "mean score: -9.876501\n",
      "scorc/reward: 10.043945\n",
      "death rate: 0.14811198\n",
      "best_death_rate: 0.14128125\n",
      "---------- 24 ----------\n",
      "criticer loss: 1.5189085\n",
      "Controller Loss: 7.988336\n",
      "mean rewards: -0.98257977\n",
      "mean score: -8.066164\n",
      "scorc/reward: 8.209169\n",
      "death rate: 0.148875\n",
      "best_death_rate: 0.14128125\n",
      "---------- 25 ----------\n",
      "criticer loss: 1.4713135\n",
      "Controller Loss: 8.96227\n",
      "mean rewards: -0.9018724\n",
      "mean score: -8.99768\n",
      "scorc/reward: 9.976666\n",
      "death rate: 0.14890626\n",
      "best_death_rate: 0.14128125\n",
      "---------- 26 ----------\n",
      "criticer loss: 1.4570276\n",
      "Controller Loss: 6.6442313\n",
      "mean rewards: -0.58175987\n",
      "mean score: -6.6708164\n",
      "scorc/reward: 11.466615\n",
      "death rate: 0.14696759\n",
      "best_death_rate: 0.14128125\n",
      "---------- 27 ----------\n",
      "criticer loss: 1.4133228\n",
      "Controller Loss: 9.553823\n",
      "mean rewards: -1.2012514\n",
      "mean score: -9.670714\n",
      "scorc/reward: 8.050533\n",
      "death rate: 0.14908482\n",
      "best_death_rate: 0.14128125\n",
      "---------- 28 ----------\n",
      "criticer loss: 1.4022354\n",
      "Controller Loss: 9.022681\n",
      "mean rewards: -0.8107191\n",
      "mean score: -9.079551\n",
      "scorc/reward: 11.19938\n",
      "death rate: 0.14856681\n",
      "best_death_rate: 0.14128125\n",
      "---------- 29 ----------\n",
      "criticer loss: 1.460425\n",
      "Controller Loss: 10.404497\n",
      "mean rewards: -1.1572177\n",
      "mean score: -10.486111\n",
      "scorc/reward: 9.061484\n",
      "death rate: 0.15016666\n",
      "best_death_rate: 0.14128125\n",
      "---------- 30 ----------\n",
      "criticer loss: 1.2222192\n",
      "Controller Loss: 6.522946\n",
      "mean rewards: -0.57290196\n",
      "mean score: -6.5532584\n",
      "scorc/reward: 11.438708\n",
      "death rate: 0.14840727\n",
      "best_death_rate: 0.14128125\n",
      "---------- 31 ----------\n",
      "criticer loss: 1.5136722\n",
      "Controller Loss: 6.110466\n",
      "mean rewards: -0.66172147\n",
      "mean score: -6.1428475\n",
      "scorc/reward: 9.283132\n",
      "death rate: 0.14727539\n",
      "best_death_rate: 0.14128125\n",
      "---------- 32 ----------\n",
      "criticer loss: 1.3928354\n",
      "Controller Loss: 7.8127346\n",
      "mean rewards: -0.76230717\n",
      "mean score: -7.8614807\n",
      "scorc/reward: 10.312747\n",
      "death rate: 0.146714\n",
      "best_death_rate: 0.14128125\n",
      "---------- 33 ----------\n",
      "criticer loss: 1.3556397\n",
      "Controller Loss: 7.267301\n",
      "mean rewards: -0.6488089\n",
      "mean score: -7.3352146\n",
      "scorc/reward: 11.305663\n",
      "death rate: 0.14557904\n",
      "best_death_rate: 0.14128125\n",
      "---------- 34 ----------\n",
      "criticer loss: 1.1592479\n",
      "Controller Loss: 8.899008\n",
      "mean rewards: -1.1404365\n",
      "mean score: -8.972817\n",
      "scorc/reward: 7.86788\n",
      "death rate: 0.14704464\n",
      "best_death_rate: 0.14128125\n",
      "---------- 35 ----------\n",
      "criticer loss: 1.4487723\n",
      "Controller Loss: 9.415438\n",
      "mean rewards: -0.93609226\n",
      "mean score: -9.484052\n",
      "scorc/reward: 10.131536\n",
      "death rate: 0.14736977\n",
      "best_death_rate: 0.14128125\n",
      "---------- 36 ----------\n",
      "criticer loss: 1.4730095\n",
      "Controller Loss: 8.847857\n",
      "mean rewards: -0.8604208\n",
      "mean score: -8.878436\n",
      "scorc/reward: 10.318714\n",
      "death rate: 0.14730573\n",
      "best_death_rate: 0.14128125\n",
      "---------- 37 ----------\n",
      "criticer loss: 1.3579509\n",
      "Controller Loss: 8.528527\n",
      "mean rewards: -0.6396665\n",
      "mean score: -8.52624\n",
      "scorc/reward: 13.329197\n",
      "death rate: 0.14615129\n",
      "best_death_rate: 0.14128125\n",
      "---------- 38 ----------\n",
      "criticer loss: 1.3492057\n",
      "Controller Loss: 8.6032295\n",
      "mean rewards: -0.89246655\n",
      "mean score: -8.612555\n",
      "scorc/reward: 9.650283\n",
      "death rate: 0.14631408\n",
      "best_death_rate: 0.14128125\n",
      "---------- 39 ----------\n",
      "criticer loss: 1.2733111\n",
      "Controller Loss: 6.9811954\n",
      "mean rewards: -0.56983274\n",
      "mean score: -6.994477\n",
      "scorc/reward: 12.274613\n",
      "death rate: 0.14502344\n",
      "best_death_rate: 0.14128125\n",
      "---------- 40 ----------\n",
      "criticer loss: 1.4450045\n",
      "Controller Loss: 9.702505\n",
      "mean rewards: -0.9068809\n",
      "mean score: -9.7223425\n",
      "scorc/reward: 10.720638\n",
      "death rate: 0.14525151\n",
      "best_death_rate: 0.14128125\n",
      "---------- 41 ----------\n",
      "criticer loss: 1.021352\n",
      "Controller Loss: 8.617307\n",
      "mean rewards: -0.8838575\n",
      "mean score: -8.63443\n",
      "scorc/reward: 9.76903\n",
      "death rate: 0.14540923\n",
      "best_death_rate: 0.14128125\n",
      "---------- 42 ----------\n",
      "criticer loss: 1.2887454\n",
      "Controller Loss: 7.6435885\n",
      "mean rewards: -0.4946031\n",
      "mean score: -7.643431\n",
      "scorc/reward: 15.453667\n",
      "death rate: 0.14389534\n",
      "best_death_rate: 0.14128125\n",
      "---------- 43 ----------\n",
      "criticer loss: 1.2222258\n",
      "Controller Loss: 11.275369\n",
      "mean rewards: -1.0269041\n",
      "mean score: -11.311656\n",
      "scorc/reward: 11.0153\n",
      "death rate: 0.14459516\n",
      "best_death_rate: 0.14128125\n",
      "---------- 44 ----------\n",
      "criticer loss: 1.3378509\n",
      "Controller Loss: 9.760908\n",
      "mean rewards: -0.92354023\n",
      "mean score: -9.770519\n",
      "scorc/reward: 10.579419\n",
      "death rate: 0.1449236\n",
      "best_death_rate: 0.14128125\n",
      "---------- 45 ----------\n",
      "criticer loss: 1.1938671\n",
      "Controller Loss: 7.618324\n",
      "mean rewards: -0.55127746\n",
      "mean score: -7.580835\n",
      "scorc/reward: 13.751397\n",
      "death rate: 0.14380433\n",
      "best_death_rate: 0.14128125\n",
      "---------- 46 ----------\n",
      "criticer loss: 1.1749539\n",
      "Controller Loss: 7.899908\n",
      "mean rewards: -0.41949737\n",
      "mean score: -7.8767724\n",
      "scorc/reward: 18.776691\n",
      "death rate: 0.14216754\n",
      "best_death_rate: 0.14128125\n",
      "---------- 47 ----------\n",
      "criticer loss: 1.114178\n",
      "Controller Loss: 10.411862\n",
      "mean rewards: -0.8113887\n",
      "mean score: -10.405784\n",
      "scorc/reward: 12.82466\n",
      "death rate: 0.14208333\n",
      "best_death_rate: 0.14128125\n",
      "---------- 48 ----------\n",
      "criticer loss: 1.1207619\n",
      "Controller Loss: 10.779489\n",
      "mean rewards: -0.4951805\n",
      "mean score: -10.688224\n",
      "scorc/reward: 21.584501\n",
      "death rate: 0.14077169\n",
      "best_death_rate: 0.14077169\n",
      "---------- 49 ----------\n",
      "criticer loss: 1.1193405\n",
      "Controller Loss: 6.4516373\n",
      "mean rewards: -0.41705343\n",
      "mean score: -6.3951187\n",
      "scorc/reward: 15.334051\n",
      "death rate: 0.13938124\n",
      "best_death_rate: 0.13938124\n",
      "---------- 50 ----------\n",
      "criticer loss: 1.0702853\n",
      "Controller Loss: 9.558789\n",
      "mean rewards: -0.53445494\n",
      "mean score: -9.474425\n",
      "scorc/reward: 17.727266\n",
      "death rate: 0.137925\n",
      "best_death_rate: 0.137925\n",
      "---------- 51 ----------\n",
      "criticer loss: 1.121466\n",
      "Controller Loss: 11.758813\n",
      "mean rewards: -0.75610363\n",
      "mean score: -11.72643\n",
      "scorc/reward: 15.509026\n",
      "death rate: 0.13731875\n",
      "best_death_rate: 0.13731875\n",
      "---------- 52 ----------\n",
      "criticer loss: 0.88405085\n",
      "Controller Loss: 9.155136\n",
      "mean rewards: -0.32620132\n",
      "mean score: -9.064858\n",
      "scorc/reward: 27.789154\n",
      "death rate: 0.13433124\n",
      "best_death_rate: 0.13433124\n",
      "---------- 53 ----------\n",
      "criticer loss: 0.888456\n",
      "Controller Loss: 11.228311\n",
      "mean rewards: -0.6668164\n",
      "mean score: -11.1681\n",
      "scorc/reward: 16.748388\n",
      "death rate: 0.1331375\n",
      "best_death_rate: 0.1331375\n",
      "---------- 54 ----------\n",
      "criticer loss: 0.70452243\n",
      "Controller Loss: 11.012562\n",
      "mean rewards: -0.40419036\n",
      "mean score: -10.91586\n",
      "scorc/reward: 27.006731\n",
      "death rate: 0.1321\n",
      "best_death_rate: 0.1321\n",
      "---------- 55 ----------\n",
      "criticer loss: 0.9284771\n",
      "Controller Loss: 5.9644213\n",
      "mean rewards: -0.157896\n",
      "mean score: -5.930079\n",
      "scorc/reward: 37.556866\n",
      "death rate: 0.13039376\n",
      "best_death_rate: 0.13039376\n",
      "---------- 56 ----------\n",
      "criticer loss: 0.7139712\n",
      "Controller Loss: 8.367871\n",
      "mean rewards: -0.4665238\n",
      "mean score: -8.311832\n",
      "scorc/reward: 17.816525\n",
      "death rate: 0.13010626\n",
      "best_death_rate: 0.13010626\n",
      "---------- 57 ----------\n",
      "criticer loss: 0.80851614\n",
      "Controller Loss: 10.9319515\n",
      "mean rewards: -0.3005089\n",
      "mean score: -10.812053\n",
      "scorc/reward: 35.97914\n",
      "death rate: 0.1277875\n",
      "best_death_rate: 0.1277875\n",
      "---------- 58 ----------\n",
      "criticer loss: 0.83252573\n",
      "Controller Loss: 9.630586\n",
      "mean rewards: -0.47275025\n",
      "mean score: -9.563314\n",
      "scorc/reward: 20.229105\n",
      "death rate: 0.1264625\n",
      "best_death_rate: 0.1264625\n",
      "---------- 59 ----------\n",
      "criticer loss: 0.8113009\n",
      "Controller Loss: 11.268655\n",
      "mean rewards: -0.54408324\n",
      "mean score: -11.158458\n",
      "scorc/reward: 20.508732\n",
      "death rate: 0.12621875\n",
      "best_death_rate: 0.12621875\n",
      "---------- 60 ----------\n",
      "criticer loss: 0.7283631\n",
      "Controller Loss: 10.626162\n",
      "mean rewards: -0.55873394\n",
      "mean score: -10.575077\n",
      "scorc/reward: 18.926857\n",
      "death rate: 0.124568745\n",
      "best_death_rate: 0.124568745\n",
      "---------- 61 ----------\n",
      "criticer loss: 0.58927774\n",
      "Controller Loss: 7.032635\n",
      "mean rewards: -0.25017014\n",
      "mean score: -6.9621525\n",
      "scorc/reward: 27.82967\n",
      "death rate: 0.12238124\n",
      "best_death_rate: 0.12238124\n",
      "---------- 62 ----------\n",
      "criticer loss: 0.84707224\n",
      "Controller Loss: 6.933884\n",
      "mean rewards: -0.14334027\n",
      "mean score: -6.8553653\n",
      "scorc/reward: 47.825813\n",
      "death rate: 0.11934375\n",
      "best_death_rate: 0.11934375\n",
      "---------- 63 ----------\n",
      "criticer loss: 0.85852605\n",
      "Controller Loss: 7.618971\n",
      "mean rewards: -0.14978534\n",
      "mean score: -7.5278788\n",
      "scorc/reward: 50.257782\n",
      "death rate: 0.116725005\n",
      "best_death_rate: 0.116725005\n",
      "---------- 64 ----------\n",
      "criticer loss: 0.6237187\n",
      "Controller Loss: 12.155574\n",
      "mean rewards: -0.3135675\n",
      "mean score: -12.100077\n",
      "scorc/reward: 38.58843\n",
      "death rate: 0.11445\n",
      "best_death_rate: 0.11445\n",
      "---------- 65 ----------\n",
      "criticer loss: 0.6756472\n",
      "Controller Loss: 8.870623\n",
      "mean rewards: -0.41112316\n",
      "mean score: -8.784288\n",
      "scorc/reward: 21.366562\n",
      "death rate: 0.11287499\n",
      "best_death_rate: 0.11287499\n",
      "---------- 66 ----------\n",
      "criticer loss: 0.81592846\n",
      "Controller Loss: 7.855561\n",
      "mean rewards: -0.30908832\n",
      "mean score: -7.7958713\n",
      "scorc/reward: 25.222149\n",
      "death rate: 0.11121875\n",
      "best_death_rate: 0.11121875\n",
      "---------- 67 ----------\n",
      "criticer loss: 0.53050137\n",
      "Controller Loss: 6.627019\n",
      "mean rewards: -0.29761776\n",
      "mean score: -6.592752\n",
      "scorc/reward: 22.151741\n",
      "death rate: 0.10897499\n",
      "best_death_rate: 0.10897499\n",
      "---------- 68 ----------\n",
      "criticer loss: 0.6071241\n",
      "Controller Loss: 8.467721\n",
      "mean rewards: -0.49575102\n",
      "mean score: -8.441555\n",
      "scorc/reward: 17.027811\n",
      "death rate: 0.10843125\n",
      "best_death_rate: 0.10843125\n",
      "---------- 69 ----------\n",
      "criticer loss: 0.65350735\n",
      "Controller Loss: 6.15428\n",
      "mean rewards: -0.22272907\n",
      "mean score: -6.129868\n",
      "scorc/reward: 27.521635\n",
      "death rate: 0.10593749\n",
      "best_death_rate: 0.10593749\n",
      "---------- 70 ----------\n",
      "criticer loss: 0.5193548\n",
      "Controller Loss: 4.4420424\n",
      "mean rewards: -0.12650266\n",
      "mean score: -4.423874\n",
      "scorc/reward: 34.9706\n",
      "death rate: 0.10366249\n",
      "best_death_rate: 0.10366249\n",
      "---------- 71 ----------\n",
      "criticer loss: 0.4817334\n",
      "Controller Loss: 4.1800184\n",
      "mean rewards: -0.18390255\n",
      "mean score: -4.150598\n",
      "scorc/reward: 22.569551\n",
      "death rate: 0.1011875\n",
      "best_death_rate: 0.1011875\n",
      "---------- 72 ----------\n",
      "criticer loss: 0.59717876\n",
      "Controller Loss: 7.9284034\n",
      "mean rewards: -0.542838\n",
      "mean score: -7.868747\n",
      "scorc/reward: 14.495572\n",
      "death rate: 0.09904376\n",
      "best_death_rate: 0.09904376\n",
      "---------- 73 ----------\n",
      "criticer loss: 0.54681\n",
      "Controller Loss: 9.064782\n",
      "mean rewards: -0.2886608\n",
      "mean score: -9.036121\n",
      "scorc/reward: 31.303598\n",
      "death rate: 0.09657499\n",
      "best_death_rate: 0.09657499\n",
      "---------- 74 ----------\n",
      "criticer loss: 0.5630714\n",
      "Controller Loss: 5.4125743\n",
      "mean rewards: -0.19456962\n",
      "mean score: -5.3840394\n",
      "scorc/reward: 27.671534\n",
      "death rate: 0.09378124\n",
      "best_death_rate: 0.09378124\n",
      "---------- 75 ----------\n",
      "criticer loss: 0.6015323\n",
      "Controller Loss: 3.47146\n",
      "mean rewards: -0.1714394\n",
      "mean score: -3.4387639\n",
      "scorc/reward: 20.058191\n",
      "death rate: 0.09125\n",
      "best_death_rate: 0.09125\n",
      "---------- 76 ----------\n",
      "criticer loss: 1.6942396\n",
      "Controller Loss: 7.1748486\n",
      "mean rewards: -0.45345792\n",
      "mean score: -7.0900793\n",
      "scorc/reward: 15.635584\n",
      "death rate: 0.09074375\n",
      "best_death_rate: 0.09074375\n",
      "---------- 77 ----------\n",
      "criticer loss: 0.6798896\n",
      "Controller Loss: 3.5063994\n",
      "mean rewards: -0.26558843\n",
      "mean score: -3.4818976\n",
      "scorc/reward: 13.110126\n",
      "death rate: 0.08743749\n",
      "best_death_rate: 0.08743749\n",
      "---------- 78 ----------\n",
      "criticer loss: 0.5086168\n",
      "Controller Loss: 4.8649273\n",
      "mean rewards: -0.41331595\n",
      "mean score: -4.846091\n",
      "scorc/reward: 11.724907\n",
      "death rate: 0.08611874\n",
      "best_death_rate: 0.08611874\n",
      "---------- 79 ----------\n",
      "criticer loss: 0.36088863\n",
      "Controller Loss: 3.6865387\n",
      "mean rewards: -0.2758086\n",
      "mean score: -3.6747966\n",
      "scorc/reward: 13.323721\n",
      "death rate: 0.0830625\n",
      "best_death_rate: 0.0830625\n",
      "---------- 80 ----------\n",
      "criticer loss: 0.5251776\n",
      "Controller Loss: 3.3985476\n",
      "mean rewards: -0.2362669\n",
      "mean score: -3.3881657\n",
      "scorc/reward: 14.340417\n",
      "death rate: 0.08190001\n",
      "best_death_rate: 0.08190001\n",
      "---------- 81 ----------\n",
      "criticer loss: 0.39019993\n",
      "Controller Loss: 1.7297285\n",
      "mean rewards: -0.10404\n",
      "mean score: -1.7045455\n",
      "scorc/reward: 16.383558\n",
      "death rate: 0.0799625\n",
      "best_death_rate: 0.0799625\n",
      "---------- 82 ----------\n",
      "criticer loss: 0.49445948\n",
      "Controller Loss: 6.743159\n",
      "mean rewards: -0.24907824\n",
      "mean score: -6.6807036\n",
      "scorc/reward: 26.821705\n",
      "death rate: 0.078056246\n",
      "best_death_rate: 0.078056246\n",
      "---------- 83 ----------\n",
      "criticer loss: 0.3828057\n",
      "Controller Loss: 7.0725827\n",
      "mean rewards: -0.3857236\n",
      "mean score: -7.02369\n",
      "scorc/reward: 18.209127\n",
      "death rate: 0.0770875\n",
      "best_death_rate: 0.0770875\n",
      "---------- 84 ----------\n",
      "criticer loss: 0.46600047\n",
      "Controller Loss: 5.585579\n",
      "mean rewards: -0.13580535\n",
      "mean score: -5.4928946\n",
      "scorc/reward: 40.44682\n",
      "death rate: 0.07339375\n",
      "best_death_rate: 0.07339375\n",
      "---------- 85 ----------\n",
      "criticer loss: 0.40996715\n",
      "Controller Loss: 4.68351\n",
      "mean rewards: -0.20814864\n",
      "mean score: -4.6299477\n",
      "scorc/reward: 22.243467\n",
      "death rate: 0.07081249\n",
      "best_death_rate: 0.07081249\n",
      "---------- 86 ----------\n",
      "criticer loss: 0.37865922\n",
      "Controller Loss: 5.3068986\n",
      "mean rewards: -0.20551603\n",
      "mean score: -5.2280893\n",
      "scorc/reward: 25.438839\n",
      "death rate: 0.06847499\n",
      "best_death_rate: 0.06847499\n",
      "---------- 87 ----------\n",
      "criticer loss: 0.38216946\n",
      "Controller Loss: 5.452932\n",
      "mean rewards: -0.2207314\n",
      "mean score: -5.387009\n",
      "scorc/reward: 24.40527\n",
      "death rate: 0.0670125\n",
      "best_death_rate: 0.0670125\n",
      "---------- 88 ----------\n",
      "criticer loss: 0.40011665\n",
      "Controller Loss: 4.436761\n",
      "mean rewards: -0.14866187\n",
      "mean score: -4.347094\n",
      "scorc/reward: 29.241488\n",
      "death rate: 0.06429375\n",
      "best_death_rate: 0.06429375\n",
      "---------- 89 ----------\n",
      "criticer loss: 0.31040844\n",
      "Controller Loss: 5.9392395\n",
      "mean rewards: -0.3085745\n",
      "mean score: -5.8796263\n",
      "scorc/reward: 19.054155\n",
      "death rate: 0.063287504\n",
      "best_death_rate: 0.063287504\n",
      "---------- 90 ----------\n",
      "criticer loss: 0.44196773\n",
      "Controller Loss: 3.17798\n",
      "mean rewards: -0.1368433\n",
      "mean score: -3.1167653\n",
      "scorc/reward: 22.776165\n",
      "death rate: 0.060549997\n",
      "best_death_rate: 0.060549997\n",
      "---------- 91 ----------\n",
      "criticer loss: 0.36989626\n",
      "Controller Loss: 6.2402806\n",
      "mean rewards: -0.37913316\n",
      "mean score: -6.1803803\n",
      "scorc/reward: 16.301344\n",
      "death rate: 0.05865625\n",
      "best_death_rate: 0.05865625\n",
      "---------- 92 ----------\n",
      "criticer loss: 0.35936853\n",
      "Controller Loss: 4.1599464\n",
      "mean rewards: -0.17581828\n",
      "mean score: -4.0918164\n",
      "scorc/reward: 23.272985\n",
      "death rate: 0.057493743\n",
      "best_death_rate: 0.057493743\n",
      "---------- 93 ----------\n",
      "criticer loss: 0.34405574\n",
      "Controller Loss: 4.79959\n",
      "mean rewards: -0.12712203\n",
      "mean score: -4.6990952\n",
      "scorc/reward: 36.965233\n",
      "death rate: 0.0541875\n",
      "best_death_rate: 0.0541875\n",
      "---------- 94 ----------\n",
      "criticer loss: 0.2518892\n",
      "Controller Loss: 5.289745\n",
      "mean rewards: -0.19479744\n",
      "mean score: -5.194191\n",
      "scorc/reward: 26.664576\n",
      "death rate: 0.051481247\n",
      "best_death_rate: 0.051481247\n",
      "---------- 95 ----------\n",
      "criticer loss: 0.32779264\n",
      "Controller Loss: 4.260232\n",
      "mean rewards: -0.15765558\n",
      "mean score: -4.192241\n",
      "scorc/reward: 26.591137\n",
      "death rate: 0.04994375\n",
      "best_death_rate: 0.04994375\n",
      "---------- 96 ----------\n",
      "criticer loss: 0.27140942\n",
      "Controller Loss: 7.3031225\n",
      "mean rewards: -0.35257316\n",
      "mean score: -7.20287\n",
      "scorc/reward: 20.429434\n",
      "death rate: 0.04959375\n",
      "best_death_rate: 0.04959375\n",
      "---------- 97 ----------\n",
      "criticer loss: 0.5795052\n",
      "Controller Loss: 7.6252275\n",
      "mean rewards: -0.42173254\n",
      "mean score: -7.565305\n",
      "scorc/reward: 17.938633\n",
      "death rate: 0.0481\n",
      "best_death_rate: 0.0481\n",
      "---------- 98 ----------\n",
      "criticer loss: 0.40250683\n",
      "Controller Loss: 3.2681222\n",
      "mean rewards: -0.1696204\n",
      "mean score: -3.2353811\n",
      "scorc/reward: 19.074245\n",
      "death rate: 0.0469625\n",
      "best_death_rate: 0.0469625\n",
      "---------- 99 ----------\n",
      "criticer loss: 0.3325569\n",
      "Controller Loss: 5.737207\n",
      "mean rewards: -0.35087898\n",
      "mean score: -5.6809983\n",
      "scorc/reward: 16.190762\n",
      "death rate: 0.04655625\n",
      "best_death_rate: 0.04655625\n",
      "---------- 100 ----------\n",
      "criticer loss: 0.31271735\n",
      "Controller Loss: 4.268097\n",
      "mean rewards: -0.24909367\n",
      "mean score: -4.233199\n",
      "scorc/reward: 16.994406\n",
      "death rate: 0.045462504\n",
      "best_death_rate: 0.045462504\n",
      "---------- 101 ----------\n",
      "criticer loss: 0.34913373\n",
      "Controller Loss: 3.6286407\n",
      "mean rewards: -0.35616213\n",
      "mean score: -3.5855882\n",
      "scorc/reward: 10.067292\n",
      "death rate: 0.043975\n",
      "best_death_rate: 0.043975\n",
      "---------- 102 ----------\n",
      "criticer loss: 0.34149224\n",
      "Controller Loss: 4.0576835\n",
      "mean rewards: -0.1883201\n",
      "mean score: -4.0071936\n",
      "scorc/reward: 21.27863\n",
      "death rate: 0.043412495\n",
      "best_death_rate: 0.043412495\n",
      "---------- 103 ----------\n",
      "criticer loss: 0.25905004\n",
      "Controller Loss: 5.267858\n",
      "mean rewards: -0.326085\n",
      "mean score: -5.2010636\n",
      "scorc/reward: 15.950024\n",
      "death rate: 0.042075\n",
      "best_death_rate: 0.042075\n",
      "---------- 104 ----------\n",
      "criticer loss: 0.28744373\n",
      "Controller Loss: 3.2903292\n",
      "mean rewards: -0.18637803\n",
      "mean score: -3.2512028\n",
      "scorc/reward: 17.444132\n",
      "death rate: 0.041281253\n",
      "best_death_rate: 0.041281253\n",
      "---------- 105 ----------\n",
      "criticer loss: 0.35797116\n",
      "Controller Loss: 3.172376\n",
      "mean rewards: -0.18304081\n",
      "mean score: -3.1230156\n",
      "scorc/reward: 17.061855\n",
      "death rate: 0.041218746\n",
      "best_death_rate: 0.041218746\n",
      "---------- 106 ----------\n",
      "criticer loss: 0.34112272\n",
      "Controller Loss: 4.8396173\n",
      "mean rewards: -0.22124667\n",
      "mean score: -4.7666893\n",
      "scorc/reward: 21.544683\n",
      "death rate: 0.040149998\n",
      "best_death_rate: 0.040149998\n",
      "---------- 107 ----------\n",
      "criticer loss: 0.33827028\n",
      "Controller Loss: 5.1486664\n",
      "mean rewards: -0.37098753\n",
      "mean score: -5.092954\n",
      "scorc/reward: 13.7281\n",
      "death rate: 0.040312495\n",
      "best_death_rate: 0.040149998\n",
      "---------- 108 ----------\n",
      "criticer loss: 0.33534914\n",
      "Controller Loss: 3.3460083\n",
      "mean rewards: -0.26168004\n",
      "mean score: -3.2562988\n",
      "scorc/reward: 12.443818\n",
      "death rate: 0.039399996\n",
      "best_death_rate: 0.039399996\n",
      "---------- 109 ----------\n",
      "criticer loss: 0.31587395\n",
      "Controller Loss: 4.727801\n",
      "mean rewards: -0.21616139\n",
      "mean score: -4.6526084\n",
      "scorc/reward: 21.523771\n",
      "death rate: 0.0381125\n",
      "best_death_rate: 0.0381125\n",
      "---------- 110 ----------\n",
      "criticer loss: 0.29094595\n",
      "Controller Loss: 5.351007\n",
      "mean rewards: -0.34556308\n",
      "mean score: -5.288744\n",
      "scorc/reward: 15.304713\n",
      "death rate: 0.037187498\n",
      "best_death_rate: 0.037187498\n",
      "---------- 111 ----------\n",
      "criticer loss: 0.2320158\n",
      "Controller Loss: 5.204163\n",
      "mean rewards: -0.3253294\n",
      "mean score: -5.1350403\n",
      "scorc/reward: 15.784126\n",
      "death rate: 0.037287496\n",
      "best_death_rate: 0.037187498\n",
      "---------- 112 ----------\n",
      "criticer loss: 0.3980865\n",
      "Controller Loss: 3.2151651\n",
      "mean rewards: -0.14693052\n",
      "mean score: -3.1567442\n",
      "scorc/reward: 21.484606\n",
      "death rate: 0.037199996\n",
      "best_death_rate: 0.037187498\n",
      "---------- 113 ----------\n",
      "criticer loss: 0.21722972\n",
      "Controller Loss: 4.193419\n",
      "mean rewards: -0.5122911\n",
      "mean score: -4.1425333\n",
      "scorc/reward: 8.086288\n",
      "death rate: 0.038399998\n",
      "best_death_rate: 0.037187498\n",
      "---------- 114 ----------\n",
      "criticer loss: 0.33925492\n",
      "Controller Loss: 5.2499723\n",
      "mean rewards: -0.49065495\n",
      "mean score: -5.2066226\n",
      "scorc/reward: 10.611577\n",
      "death rate: 0.039024998\n",
      "best_death_rate: 0.037187498\n",
      "---------- 115 ----------\n",
      "criticer loss: 0.37111112\n",
      "Controller Loss: 4.4181585\n",
      "mean rewards: -0.37313384\n",
      "mean score: -4.3430543\n",
      "scorc/reward: 11.6394005\n",
      "death rate: 0.03870625\n",
      "best_death_rate: 0.037187498\n",
      "---------- 116 ----------\n",
      "criticer loss: 0.4080603\n",
      "Controller Loss: 6.167697\n",
      "mean rewards: -0.5873509\n",
      "mean score: -6.038298\n",
      "scorc/reward: 10.280563\n",
      "death rate: 0.03956875\n",
      "best_death_rate: 0.037187498\n",
      "---------- 117 ----------\n",
      "criticer loss: 0.50669783\n",
      "Controller Loss: 4.691978\n",
      "mean rewards: -0.5796654\n",
      "mean score: -4.641199\n",
      "scorc/reward: 8.006686\n",
      "death rate: 0.040425\n",
      "best_death_rate: 0.037187498\n",
      "---------- 118 ----------\n",
      "criticer loss: 0.4809622\n",
      "Controller Loss: 2.67008\n",
      "mean rewards: -0.62044936\n",
      "mean score: -2.599715\n",
      "scorc/reward: 4.190052\n",
      "death rate: 0.04065\n",
      "best_death_rate: 0.037187498\n",
      "---------- 119 ----------\n",
      "criticer loss: 0.49939606\n",
      "Controller Loss: 1.8408362\n",
      "mean rewards: -0.3115217\n",
      "mean score: -1.819638\n",
      "scorc/reward: 5.8411274\n",
      "death rate: 0.040874995\n",
      "best_death_rate: 0.037187498\n",
      "---------- 120 ----------\n",
      "criticer loss: 0.39491212\n",
      "Controller Loss: 3.1653574\n",
      "mean rewards: -0.42872772\n",
      "mean score: -3.0368052\n",
      "scorc/reward: 7.083296\n",
      "death rate: 0.04174375\n",
      "best_death_rate: 0.037187498\n",
      "---------- 121 ----------\n",
      "criticer loss: 0.6160273\n",
      "Controller Loss: 3.6792748\n",
      "mean rewards: -0.40299702\n",
      "mean score: -3.571505\n",
      "scorc/reward: 8.862362\n",
      "death rate: 0.0423125\n",
      "best_death_rate: 0.037187498\n",
      "---------- 122 ----------\n",
      "criticer loss: 1.0005927\n",
      "Controller Loss: 2.591253\n",
      "mean rewards: -0.38975695\n",
      "mean score: -2.525331\n",
      "scorc/reward: 6.4792457\n",
      "death rate: 0.04153125\n",
      "best_death_rate: 0.037187498\n",
      "---------- 123 ----------\n",
      "criticer loss: 0.6234771\n",
      "Controller Loss: 4.115717\n",
      "mean rewards: -0.69214064\n",
      "mean score: -4.078206\n",
      "scorc/reward: 5.892164\n",
      "death rate: 0.042874996\n",
      "best_death_rate: 0.037187498\n",
      "---------- 124 ----------\n",
      "criticer loss: 2.5188844\n",
      "Controller Loss: 5.471021\n",
      "mean rewards: -0.55311066\n",
      "mean score: -5.378547\n",
      "scorc/reward: 9.724179\n",
      "death rate: 0.043912496\n",
      "best_death_rate: 0.037187498\n",
      "---------- 125 ----------\n",
      "criticer loss: 0.8721451\n",
      "Controller Loss: 3.0988946\n",
      "mean rewards: -0.77526045\n",
      "mean score: -3.0616775\n",
      "scorc/reward: 3.9492245\n",
      "death rate: 0.04589999\n",
      "best_death_rate: 0.037187498\n",
      "---------- 126 ----------\n",
      "criticer loss: 0.46731558\n",
      "Controller Loss: 4.9496684\n",
      "mean rewards: -0.6135582\n",
      "mean score: -4.838039\n",
      "scorc/reward: 7.885216\n",
      "death rate: 0.0462625\n",
      "best_death_rate: 0.037187498\n",
      "---------- 127 ----------\n",
      "criticer loss: 0.8703235\n",
      "Controller Loss: 3.5620513\n",
      "mean rewards: -0.41411796\n",
      "mean score: -3.4912276\n",
      "scorc/reward: 8.430514\n",
      "death rate: 0.04663125\n",
      "best_death_rate: 0.037187498\n",
      "---------- 128 ----------\n",
      "criticer loss: 0.795936\n",
      "Controller Loss: 4.4353533\n",
      "mean rewards: -0.6299065\n",
      "mean score: -4.3476176\n",
      "scorc/reward: 6.902005\n",
      "death rate: 0.04714375\n",
      "best_death_rate: 0.037187498\n",
      "---------- 129 ----------\n",
      "criticer loss: 0.9639599\n",
      "Controller Loss: 4.371469\n",
      "mean rewards: -0.5936711\n",
      "mean score: -4.2783575\n",
      "scorc/reward: 7.2066126\n",
      "death rate: 0.048056245\n",
      "best_death_rate: 0.037187498\n",
      "---------- 130 ----------\n",
      "criticer loss: 0.8340815\n",
      "Controller Loss: 5.3907423\n",
      "mean rewards: -0.8212877\n",
      "mean score: -5.308989\n",
      "scorc/reward: 6.464226\n",
      "death rate: 0.049862493\n",
      "best_death_rate: 0.037187498\n",
      "---------- 131 ----------\n",
      "criticer loss: 0.73589295\n",
      "Controller Loss: 7.4029\n",
      "mean rewards: -0.8620216\n",
      "mean score: -7.2725277\n",
      "scorc/reward: 8.436596\n",
      "death rate: 0.05221875\n",
      "best_death_rate: 0.037187498\n",
      "---------- 132 ----------\n",
      "criticer loss: 1.1405858\n",
      "Controller Loss: 3.915547\n",
      "mean rewards: -0.68553144\n",
      "mean score: -3.8205388\n",
      "scorc/reward: 5.5731053\n",
      "death rate: 0.05368125\n",
      "best_death_rate: 0.037187498\n",
      "---------- 133 ----------\n",
      "criticer loss: 0.94779474\n",
      "Controller Loss: 5.2261205\n",
      "mean rewards: -0.6312346\n",
      "mean score: -5.1535816\n",
      "scorc/reward: 8.1642885\n",
      "death rate: 0.05443125\n",
      "best_death_rate: 0.037187498\n",
      "---------- 134 ----------\n",
      "criticer loss: 1.2453932\n",
      "Controller Loss: 6.813431\n",
      "mean rewards: -0.8714935\n",
      "mean score: -6.713394\n",
      "scorc/reward: 7.703321\n",
      "death rate: 0.056943744\n",
      "best_death_rate: 0.037187498\n",
      "---------- 135 ----------\n",
      "criticer loss: 0.98664856\n",
      "Controller Loss: 7.3311095\n",
      "mean rewards: -0.76362455\n",
      "mean score: -7.19817\n",
      "scorc/reward: 9.426321\n",
      "death rate: 0.058656253\n",
      "best_death_rate: 0.037187498\n",
      "---------- 136 ----------\n",
      "criticer loss: 1.1032989\n",
      "Controller Loss: 7.373767\n",
      "mean rewards: -0.9354736\n",
      "mean score: -7.2407126\n",
      "scorc/reward: 7.740157\n",
      "death rate: 0.06113125\n",
      "best_death_rate: 0.037187498\n",
      "---------- 137 ----------\n",
      "criticer loss: 0.83454335\n",
      "Controller Loss: 6.622269\n",
      "mean rewards: -0.6748955\n",
      "mean score: -6.5029893\n",
      "scorc/reward: 9.63555\n",
      "death rate: 0.062606245\n",
      "best_death_rate: 0.037187498\n",
      "---------- 138 ----------\n",
      "criticer loss: 1.2697672\n",
      "Controller Loss: 7.140853\n",
      "mean rewards: -0.7845338\n",
      "mean score: -7.073773\n",
      "scorc/reward: 9.01653\n",
      "death rate: 0.0647875\n",
      "best_death_rate: 0.037187498\n",
      "---------- 139 ----------\n",
      "criticer loss: 0.9651205\n",
      "Controller Loss: 10.932041\n",
      "mean rewards: -1.0414752\n",
      "mean score: -10.801589\n",
      "scorc/reward: 10.371432\n",
      "death rate: 0.06724375\n",
      "best_death_rate: 0.037187498\n",
      "---------- 140 ----------\n",
      "criticer loss: 0.9781853\n",
      "Controller Loss: 9.2310295\n",
      "mean rewards: -0.9139015\n",
      "mean score: -9.12665\n",
      "scorc/reward: 9.986469\n",
      "death rate: 0.06978125\n",
      "best_death_rate: 0.037187498\n",
      "---------- 141 ----------\n",
      "criticer loss: 0.9850052\n",
      "Controller Loss: 9.709675\n",
      "mean rewards: -0.8727434\n",
      "mean score: -9.6071005\n",
      "scorc/reward: 11.007933\n",
      "death rate: 0.07138125\n",
      "best_death_rate: 0.037187498\n",
      "---------- 142 ----------\n",
      "criticer loss: 1.2578253\n",
      "Controller Loss: 10.540318\n",
      "mean rewards: -0.99989563\n",
      "mean score: -10.426057\n",
      "scorc/reward: 10.427146\n",
      "death rate: 0.074125\n",
      "best_death_rate: 0.037187498\n",
      "---------- 143 ----------\n",
      "criticer loss: 1.2598692\n",
      "Controller Loss: 9.342678\n",
      "mean rewards: -1.2233143\n",
      "mean score: -9.238564\n",
      "scorc/reward: 7.552077\n",
      "death rate: 0.078006245\n",
      "best_death_rate: 0.037187498\n",
      "---------- 144 ----------\n",
      "criticer loss: 1.0423093\n",
      "Controller Loss: 10.328932\n",
      "mean rewards: -0.85962707\n",
      "mean score: -10.169986\n",
      "scorc/reward: 11.830695\n",
      "death rate: 0.080225\n",
      "best_death_rate: 0.037187498\n",
      "---------- 145 ----------\n",
      "criticer loss: 1.239308\n",
      "Controller Loss: 11.2539215\n",
      "mean rewards: -1.0496894\n",
      "mean score: -11.1401415\n",
      "scorc/reward: 10.612798\n",
      "death rate: 0.083325\n",
      "best_death_rate: 0.037187498\n",
      "---------- 146 ----------\n",
      "criticer loss: 0.9835381\n",
      "Controller Loss: 10.798768\n",
      "mean rewards: -0.87607116\n",
      "mean score: -10.634893\n",
      "scorc/reward: 12.139303\n",
      "death rate: 0.08513124\n",
      "best_death_rate: 0.037187498\n",
      "---------- 147 ----------\n",
      "criticer loss: 1.22384\n",
      "Controller Loss: 12.991343\n",
      "mean rewards: -0.9556424\n",
      "mean score: -12.857519\n",
      "scorc/reward: 13.454321\n",
      "death rate: 0.0869625\n",
      "best_death_rate: 0.037187498\n",
      "---------- 148 ----------\n",
      "criticer loss: 1.4161078\n",
      "Controller Loss: 12.847804\n",
      "mean rewards: -1.0164366\n",
      "mean score: -12.671472\n",
      "scorc/reward: 12.466564\n",
      "death rate: 0.08985001\n",
      "best_death_rate: 0.037187498\n",
      "---------- 149 ----------\n",
      "criticer loss: 1.4350624\n",
      "Controller Loss: 14.008672\n",
      "mean rewards: -1.0114484\n",
      "mean score: -13.856313\n",
      "scorc/reward: 13.699476\n",
      "death rate: 0.092106245\n",
      "best_death_rate: 0.037187498\n",
      "---------- 150 ----------\n",
      "criticer loss: 1.1973895\n",
      "Controller Loss: 11.782298\n",
      "mean rewards: -1.1042788\n",
      "mean score: -11.663855\n",
      "scorc/reward: 10.562418\n",
      "death rate: 0.09507499\n",
      "best_death_rate: 0.037187498\n",
      "---------- 151 ----------\n",
      "criticer loss: 1.4202045\n",
      "Controller Loss: 11.306556\n",
      "mean rewards: -0.8443195\n",
      "mean score: -11.181074\n",
      "scorc/reward: 13.242705\n",
      "death rate: 0.09670625\n",
      "best_death_rate: 0.037187498\n",
      "---------- 152 ----------\n",
      "criticer loss: 1.3230294\n",
      "Controller Loss: 12.190544\n",
      "mean rewards: -0.907206\n",
      "mean score: -12.080645\n",
      "scorc/reward: 13.316319\n",
      "death rate: 0.09920625\n",
      "best_death_rate: 0.037187498\n",
      "---------- 153 ----------\n",
      "criticer loss: 1.1191097\n",
      "Controller Loss: 12.52881\n",
      "mean rewards: -1.0741328\n",
      "mean score: -12.439799\n",
      "scorc/reward: 11.581248\n",
      "death rate: 0.10185624\n",
      "best_death_rate: 0.037187498\n",
      "---------- 154 ----------\n",
      "criticer loss: 1.4792805\n",
      "Controller Loss: 14.307079\n",
      "mean rewards: -1.4057101\n",
      "mean score: -14.198083\n",
      "scorc/reward: 10.100292\n",
      "death rate: 0.10614375\n",
      "best_death_rate: 0.037187498\n",
      "---------- 155 ----------\n",
      "criticer loss: 1.1918063\n",
      "Controller Loss: 14.8601465\n",
      "mean rewards: -1.0845183\n",
      "mean score: -14.692058\n",
      "scorc/reward: 13.547081\n",
      "death rate: 0.109306246\n",
      "best_death_rate: 0.037187498\n",
      "---------- 156 ----------\n",
      "criticer loss: 1.330768\n",
      "Controller Loss: 17.31\n",
      "mean rewards: -1.2969443\n",
      "mean score: -17.169079\n",
      "scorc/reward: 13.238101\n",
      "death rate: 0.11312499\n",
      "best_death_rate: 0.037187498\n",
      "---------- 157 ----------\n",
      "criticer loss: 1.2237643\n",
      "Controller Loss: 14.567588\n",
      "mean rewards: -1.0795625\n",
      "mean score: -14.366203\n",
      "scorc/reward: 13.30743\n",
      "death rate: 0.115662485\n",
      "best_death_rate: 0.037187498\n",
      "---------- 158 ----------\n",
      "criticer loss: 1.6066561\n",
      "Controller Loss: 17.18687\n",
      "mean rewards: -0.9357796\n",
      "mean score: -16.953276\n",
      "scorc/reward: 18.116741\n",
      "death rate: 0.117975004\n",
      "best_death_rate: 0.037187498\n",
      "---------- 159 ----------\n",
      "criticer loss: 1.2502304\n",
      "Controller Loss: 18.1397\n",
      "mean rewards: -1.406746\n",
      "mean score: -18.029762\n",
      "scorc/reward: 12.816644\n",
      "death rate: 0.12221875\n",
      "best_death_rate: 0.037187498\n",
      "---------- 160 ----------\n",
      "criticer loss: 1.1909145\n",
      "Controller Loss: 15.740644\n",
      "mean rewards: -1.1644065\n",
      "mean score: -15.610958\n",
      "scorc/reward: 13.406794\n",
      "death rate: 0.12521875\n",
      "best_death_rate: 0.037187498\n",
      "---------- 161 ----------\n",
      "criticer loss: 1.3452386\n",
      "Controller Loss: 11.176523\n",
      "mean rewards: -0.54925996\n",
      "mean score: -11.004717\n",
      "scorc/reward: 20.035534\n",
      "death rate: 0.12606248\n",
      "best_death_rate: 0.037187498\n",
      "---------- 162 ----------\n",
      "criticer loss: 1.4598764\n",
      "Controller Loss: 16.275145\n",
      "mean rewards: -1.075882\n",
      "mean score: -16.1055\n",
      "scorc/reward: 14.969579\n",
      "death rate: 0.129325\n",
      "best_death_rate: 0.037187498\n",
      "---------- 163 ----------\n",
      "criticer loss: 1.419937\n",
      "Controller Loss: 23.135908\n",
      "mean rewards: -1.5032513\n",
      "mean score: -22.936682\n",
      "scorc/reward: 15.258048\n",
      "death rate: 0.13280001\n",
      "best_death_rate: 0.037187498\n",
      "---------- 164 ----------\n",
      "criticer loss: 1.4485576\n",
      "Controller Loss: 14.18948\n",
      "mean rewards: -0.81337255\n",
      "mean score: -14.037028\n",
      "scorc/reward: 17.257809\n",
      "death rate: 0.13401873\n",
      "best_death_rate: 0.037187498\n",
      "---------- 165 ----------\n",
      "criticer loss: 1.3772124\n",
      "Controller Loss: 14.606995\n",
      "mean rewards: -1.0087849\n",
      "mean score: -14.439477\n",
      "scorc/reward: 14.313733\n",
      "death rate: 0.136375\n",
      "best_death_rate: 0.037187498\n",
      "---------- 166 ----------\n",
      "criticer loss: 1.4234828\n",
      "Controller Loss: 14.5977\n",
      "mean rewards: -0.79118824\n",
      "mean score: -14.422896\n",
      "scorc/reward: 18.229412\n",
      "death rate: 0.13714999\n",
      "best_death_rate: 0.037187498\n",
      "---------- 167 ----------\n",
      "criticer loss: 1.3444012\n",
      "Controller Loss: 15.60301\n",
      "mean rewards: -1.0853848\n",
      "mean score: -15.45865\n",
      "scorc/reward: 14.242552\n",
      "death rate: 0.139025\n",
      "best_death_rate: 0.037187498\n",
      "---------- 168 ----------\n",
      "criticer loss: 1.3285868\n",
      "Controller Loss: 15.306117\n",
      "mean rewards: -0.9083601\n",
      "mean score: -15.1598625\n",
      "scorc/reward: 16.689264\n",
      "death rate: 0.14017498\n",
      "best_death_rate: 0.037187498\n",
      "---------- 169 ----------\n",
      "criticer loss: 1.3299803\n",
      "Controller Loss: 18.291748\n",
      "mean rewards: -0.9224795\n",
      "mean score: -18.067629\n",
      "scorc/reward: 19.585941\n",
      "death rate: 0.14228125\n",
      "best_death_rate: 0.037187498\n",
      "---------- 170 ----------\n",
      "criticer loss: 1.5370477\n",
      "Controller Loss: 16.843386\n",
      "mean rewards: -1.1092322\n",
      "mean score: -16.678335\n",
      "scorc/reward: 15.035929\n",
      "death rate: 0.1448375\n",
      "best_death_rate: 0.037187498\n",
      "---------- 171 ----------\n",
      "criticer loss: 1.3320097\n",
      "Controller Loss: 13.423283\n",
      "mean rewards: -0.651323\n",
      "mean score: -13.300099\n",
      "scorc/reward: 20.420128\n",
      "death rate: 0.14583126\n",
      "best_death_rate: 0.037187498\n",
      "---------- 172 ----------\n",
      "criticer loss: 1.3177642\n",
      "Controller Loss: 15.737127\n",
      "mean rewards: -0.9646263\n",
      "mean score: -15.623884\n",
      "scorc/reward: 16.196825\n",
      "death rate: 0.148\n",
      "best_death_rate: 0.037187498\n",
      "---------- 173 ----------\n",
      "criticer loss: 1.517579\n",
      "Controller Loss: 14.275696\n",
      "mean rewards: -0.72645485\n",
      "mean score: -14.12209\n",
      "scorc/reward: 19.439735\n",
      "death rate: 0.1482375\n",
      "best_death_rate: 0.037187498\n",
      "---------- 174 ----------\n",
      "criticer loss: 1.2006285\n",
      "Controller Loss: 16.468891\n",
      "mean rewards: -0.8346022\n",
      "mean score: -16.250517\n",
      "scorc/reward: 19.470974\n",
      "death rate: 0.14939375\n",
      "best_death_rate: 0.037187498\n",
      "---------- 175 ----------\n",
      "criticer loss: 1.4030133\n",
      "Controller Loss: 14.895182\n",
      "mean rewards: -0.8176376\n",
      "mean score: -14.777231\n",
      "scorc/reward: 18.073082\n",
      "death rate: 0.149675\n",
      "best_death_rate: 0.037187498\n",
      "---------- 176 ----------\n",
      "criticer loss: 1.2550117\n",
      "Controller Loss: 14.664503\n",
      "mean rewards: -0.84480083\n",
      "mean score: -14.456077\n",
      "scorc/reward: 17.111816\n",
      "death rate: 0.1506875\n",
      "best_death_rate: 0.037187498\n",
      "---------- 177 ----------\n",
      "criticer loss: 1.2066815\n",
      "Controller Loss: 18.29799\n",
      "mean rewards: -1.115099\n",
      "mean score: -18.134926\n",
      "scorc/reward: 16.263063\n",
      "death rate: 0.15325\n",
      "best_death_rate: 0.037187498\n",
      "---------- 178 ----------\n",
      "criticer loss: 1.1617912\n",
      "Controller Loss: 16.81897\n",
      "mean rewards: -0.98225796\n",
      "mean score: -16.642128\n",
      "scorc/reward: 16.942726\n",
      "death rate: 0.15465625\n",
      "best_death_rate: 0.037187498\n",
      "---------- 179 ----------\n",
      "criticer loss: 1.2071143\n",
      "Controller Loss: 13.197296\n",
      "mean rewards: -0.55187166\n",
      "mean score: -12.998502\n",
      "scorc/reward: 23.553488\n",
      "death rate: 0.1546125\n",
      "best_death_rate: 0.037187498\n",
      "---------- 180 ----------\n",
      "criticer loss: 1.106386\n",
      "Controller Loss: 15.150798\n",
      "mean rewards: -0.7351364\n",
      "mean score: -14.975353\n",
      "scorc/reward: 20.370852\n",
      "death rate: 0.15446249\n",
      "best_death_rate: 0.037187498\n",
      "---------- 181 ----------\n",
      "criticer loss: 1.3831637\n",
      "Controller Loss: 13.452761\n",
      "mean rewards: -0.6061644\n",
      "mean score: -13.323131\n",
      "scorc/reward: 21.9794\n",
      "death rate: 0.15374376\n",
      "best_death_rate: 0.037187498\n",
      "---------- 182 ----------\n",
      "criticer loss: 1.1558024\n",
      "Controller Loss: 12.868933\n",
      "mean rewards: -0.5134343\n",
      "mean score: -12.727456\n",
      "scorc/reward: 24.78887\n",
      "death rate: 0.15323749\n",
      "best_death_rate: 0.037187498\n",
      "---------- 183 ----------\n",
      "criticer loss: 1.2369379\n",
      "Controller Loss: 11.273482\n",
      "mean rewards: -0.49022326\n",
      "mean score: -11.132755\n",
      "scorc/reward: 22.709562\n",
      "death rate: 0.15286875\n",
      "best_death_rate: 0.037187498\n",
      "---------- 184 ----------\n",
      "criticer loss: 1.1310691\n",
      "Controller Loss: 17.170998\n",
      "mean rewards: -1.1216885\n",
      "mean score: -16.96351\n",
      "scorc/reward: 15.123192\n",
      "death rate: 0.153875\n",
      "best_death_rate: 0.037187498\n",
      "---------- 185 ----------\n",
      "criticer loss: 1.1503537\n",
      "Controller Loss: 17.576189\n",
      "mean rewards: -1.0861722\n",
      "mean score: -17.397125\n",
      "scorc/reward: 16.016912\n",
      "death rate: 0.15523125\n",
      "best_death_rate: 0.037187498\n",
      "---------- 186 ----------\n",
      "criticer loss: 1.2773584\n",
      "Controller Loss: 17.178095\n",
      "mean rewards: -0.8546301\n",
      "mean score: -17.030344\n",
      "scorc/reward: 19.927153\n",
      "death rate: 0.15500624\n",
      "best_death_rate: 0.037187498\n",
      "---------- 187 ----------\n",
      "criticer loss: 0.9269226\n",
      "Controller Loss: 14.569251\n",
      "mean rewards: -0.7302964\n",
      "mean score: -14.402916\n",
      "scorc/reward: 19.722015\n",
      "death rate: 0.15533125\n",
      "best_death_rate: 0.037187498\n",
      "---------- 188 ----------\n",
      "criticer loss: 0.976779\n",
      "Controller Loss: 13.579335\n",
      "mean rewards: -0.8367867\n",
      "mean score: -13.397483\n",
      "scorc/reward: 16.010632\n",
      "death rate: 0.15563126\n",
      "best_death_rate: 0.037187498\n",
      "---------- 189 ----------\n",
      "criticer loss: 0.81246406\n",
      "Controller Loss: 9.619267\n",
      "mean rewards: -0.53736806\n",
      "mean score: -9.476013\n",
      "scorc/reward: 17.63412\n",
      "death rate: 0.15405\n",
      "best_death_rate: 0.037187498\n",
      "---------- 190 ----------\n",
      "criticer loss: 1.0190557\n",
      "Controller Loss: 12.73219\n",
      "mean rewards: -0.581932\n",
      "mean score: -12.525863\n",
      "scorc/reward: 21.524616\n",
      "death rate: 0.15306251\n",
      "best_death_rate: 0.037187498\n",
      "---------- 191 ----------\n",
      "criticer loss: 0.8343341\n",
      "Controller Loss: 11.263359\n",
      "mean rewards: -0.438614\n",
      "mean score: -11.054906\n",
      "scorc/reward: 25.204178\n",
      "death rate: 0.1516875\n",
      "best_death_rate: 0.037187498\n",
      "---------- 192 ----------\n",
      "criticer loss: 0.8988022\n",
      "Controller Loss: 13.561018\n",
      "mean rewards: -0.8802941\n",
      "mean score: -13.379754\n",
      "scorc/reward: 15.199187\n",
      "death rate: 0.15146874\n",
      "best_death_rate: 0.037187498\n",
      "---------- 193 ----------\n",
      "criticer loss: 0.9916844\n",
      "Controller Loss: 14.158306\n",
      "mean rewards: -0.6468563\n",
      "mean score: -13.923663\n",
      "scorc/reward: 21.525126\n",
      "death rate: 0.14946876\n",
      "best_death_rate: 0.037187498\n",
      "---------- 194 ----------\n",
      "criticer loss: 0.9830036\n",
      "Controller Loss: 10.97955\n",
      "mean rewards: -0.47674057\n",
      "mean score: -10.819448\n",
      "scorc/reward: 22.694624\n",
      "death rate: 0.14829375\n",
      "best_death_rate: 0.037187498\n",
      "---------- 195 ----------\n",
      "criticer loss: 0.84582156\n",
      "Controller Loss: 10.434331\n",
      "mean rewards: -0.47506362\n",
      "mean score: -10.262669\n",
      "scorc/reward: 21.602724\n",
      "death rate: 0.1464\n",
      "best_death_rate: 0.037187498\n",
      "---------- 196 ----------\n",
      "criticer loss: 0.8599846\n",
      "Controller Loss: 13.935626\n",
      "mean rewards: -0.7739758\n",
      "mean score: -13.720927\n",
      "scorc/reward: 17.727852\n",
      "death rate: 0.14618126\n",
      "best_death_rate: 0.037187498\n",
      "---------- 197 ----------\n",
      "criticer loss: 0.7867617\n"
     ]
    }
   ],
   "source": [
    "# Debug Nan\n",
    "# jax.config.update(\"jax_debug_nans\", True)\n",
    "\n",
    "import exp\n",
    "\n",
    "\n",
    "death_rate_buf = []\n",
    "best_death_rate = 0.5\n",
    "\n",
    "for i in range(4000):\n",
    "\n",
    "    print(\"----------\",i,\"----------\")\n",
    "    \n",
    "    criric_repeat = 16\n",
    "    if(i == 500):\n",
    "        criric_repeat = 1\n",
    "        \n",
    "    for j in range(criric_repeat):\n",
    "        batch = jit_sample(exp_pool, critic_batch_size, key)\n",
    "        key = jax.random.split(key, 1)[0]\n",
    "        \n",
    "        # criticer\n",
    "        critic_loss, critic_loss_grad = jit_critic_loss_g_value(critic_params, batch)\n",
    "        \n",
    "        # Update params\n",
    "        critic_updates, critic_opt_state = jit_critic_tx_update(critic_loss_grad, critic_opt_state)\n",
    "        critic_params = jit_apply_update(critic_params, critic_updates)\n",
    "    \n",
    "    print(\"criticer loss:\",critic_loss)\n",
    "    # controller\n",
    "    \n",
    "    # for j in range(3):\n",
    "    keys = jax.random.split(key,controller_batch_size)\n",
    "    controller_batch = jit_sample(exp_pool, controller_batch_size, key)\n",
    "    key = jax.random.split(key, 1)[0]\n",
    "    controller_loss_exps, controller_loss_grad = jit_g_loss_experience(\n",
    "        controller_params, critic_params, controller_batch, mjx_model, init_data_batch, keys)\n",
    "    controller_loss = controller_loss_exps[0]\n",
    "    exps = controller_loss_exps[1]\n",
    "        \n",
    "    # Update params\n",
    "    controller_updates, controller_opt_state = jit_controller_tx_update(controller_loss_grad, controller_opt_state)\n",
    "    controller_params = jit_apply_update(controller_params, controller_updates)\n",
    "    \n",
    "    exp_pool = jit_add_exp(memory_settings, exp_pool, exps)\n",
    "    \n",
    "    # Count Dones\n",
    "    death_rate_buf.insert(0, jp.count_nonzero( exps.dones)/(exps.dones.shape[1]*controller_batch_size))\n",
    "    death_rate_buf = death_rate_buf[:50]\n",
    "    death_rate = np.mean(death_rate_buf)\n",
    "    \n",
    "    print(\"Controller Loss:\", controller_loss)\n",
    "    mean_reward = jp.mean(exps.rewards)\n",
    "    print(\"mean rewards:\", mean_reward)\n",
    "    mean_score = jp.mean(jit_v_criticer(critic_params, exps.states))\n",
    "    print(\"mean score:\", mean_score)\n",
    "    print(\"scorc/reward:\", mean_score/mean_reward)\n",
    "    print(\"death rate:\", death_rate)\n",
    "    \n",
    "    if(best_death_rate > death_rate): best_death_rate = death_rate\n",
    "    print(\"best_death_rate:\", best_death_rate)\n",
    "    # add exps\n",
    "    \n",
    "    if(i%20 == 0):\n",
    "        plt.figure()\n",
    "        plt.plot(exp_pool.rewards)\n",
    "        plt.plot()\n",
    "        # plt.plot(exp_pool.rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the model and controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mujoco.viewer\n",
    "import time\n",
    "\n",
    "\n",
    "# Disable tendon\n",
    "opt = mjx_model.opt.replace(disableflags = mjx_model.opt.disableflags |mujoco.mjtDisableBit.mjDSBL_PASSIVE)\n",
    "mjx_model = mjx_model.replace(opt=opt)\n",
    "\n",
    "mjx_data = mjx.make_data(mjx_model)\n",
    "mj_data = mujoco.MjData(mj_model)\n",
    "\n",
    "# Load the Keyframe\n",
    "mjx_data = mjx_data.replace(qpos = mj_model.key_qpos[0])\n",
    "mj_data.qpos = mj_model.key_qpos[0]\n",
    "\n",
    "# Calculate equilibrum\n",
    "mjx_data = acceleration_mtu.calc_equilibrium(mjx_model, mjx_data)\n",
    "\n",
    "previous_frame_time = time.time()\n",
    "i = 0\n",
    "key = jax.random.key(334)\n",
    "with mujoco.viewer.launch_passive(mj_model, mj_data) as viewer:\n",
    "    while viewer.is_running():\n",
    "        # Update mjx_data from mj_data. The mj_data was modified by the viewer\n",
    "        # mjx_data = mjx_data.replace(ctrl=mj_data.ctrl, xfrc_applied=mj_data.xfrc_applied)\n",
    "        # Use the nerual network to generate ctrl signal\n",
    "        \n",
    "        mjx_data = mjx_data.replace(xfrc_applied=jp.array(mj_data.xfrc_applied, dtype=jp.float32))\n",
    "        \n",
    "        # Generate key\n",
    "        key = jax.random.split(key,1)[0]\n",
    "        # xfrc = jax.random.uniform(key,(mjx_model.nbody, 6), minval=-10, maxval=10)\n",
    "        # mjx_data = mjx_data.replace(xfrc_applied=xfrc)\n",
    "        mjx_data = mjx_data.replace(\n",
    "            qpos= jp.array(mj_data.qpos, dtype=jp.float32),\n",
    "            qvel= jp.array(mj_data.qvel, dtype=jp.float32),\n",
    "            time = jp.array(mj_data.time, dtype=jp.float32))\n",
    "        \n",
    "        # Update mjx_model from mj_model\n",
    "        mjx_model = mjx_model.tree_replace({\n",
    "            'opt.gravity': jp.array(mj_model.opt.gravity, dtype=jp.float32),\n",
    "            'opt.tolerance': jp.array(mj_model.opt.tolerance, dtype=jp.float32),\n",
    "            'opt.ls_tolerance': jp.array(mj_model.opt.ls_tolerance, dtype=jp.float32),\n",
    "            'opt.timestep': jp.array(mj_model.opt.timestep, dtype=jp.float32),\n",
    "        })\n",
    "        \n",
    "        # mjx_data = mjx_step(mjx_model, mjx_data)\n",
    "        # mjx_data, loss, exps = jit_nn_multi_steps(controller_params, mjx_model, mjx_data, key)\n",
    "        mjx_data, key, act = jit_nn_mjx_one_step_no_random(controller_params, mjx_model, mjx_data, key)\n",
    "        mjx.get_data_into(mj_data, mj_model, mjx_data)\n",
    "        \n",
    "        # Record the current time at the start of this frame\n",
    "        current_frame_time = time.time()\n",
    "    \n",
    "        # Calculate the difference in time from the last frame\n",
    "        time_between_frames = current_frame_time - previous_frame_time\n",
    "    \n",
    "        # Print the time between frames\n",
    "        print(f\"Time between frames: {time_between_frames} seconds\")\n",
    "        previous_frame_time = current_frame_time\n",
    "        \n",
    "        # print(\"ACT:\", mjx_data.biomtu.act)\n",
    "        # print(mjx_data.qpos)\n",
    "        # print(mj_data.sen)  \n",
    "        print(mjx_data.sensordata[2])\n",
    "        print(mjx_data.biomtu.act)\n",
    "        # print(len(mjx_data.qvel))\n",
    "        viewer.sync()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biomujoco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
